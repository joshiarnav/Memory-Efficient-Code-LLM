{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZEuAhQwdgp4",
        "outputId": "e32ce928-1c67-4763-aafb-c71247f3211e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAX0Pe0WdzI2",
        "outputId": "5fdbeeb3-c185-4d32-c7d3-5df19b1762c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/CS 6158/CS6158 Research Project/src\n"
          ]
        }
      ],
      "source": [
        "%cd gdrive/MyDrive/CS 6158/CS6158 Research Project/src"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwDM3dN5N4J-",
        "outputId": "caae436d-bc70-4ee1-e739-b2953836caf8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/CS 6158/CS6158 Research Project/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "# userdata.get('huggingface_token')"
      ],
      "metadata": {
        "id": "b4j37VXMKBVk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token {userdata.get('HF_TOKEN')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjK4tt0xGuC8",
        "outputId": "e2ba00dc-6fe1-40d4-834d-cfcee14073cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "The token `NLP` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `NLP`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uW__zSloLUZ",
        "outputId": "079e8bc3-ca3a-4eea-ee93-76072404238a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;31mWarning\u001b[0m: Running in non-interactive mode because `stdin` is not a TTY.\n",
            "\u001b[1;34m==>\u001b[1;39m Checking for `sudo` access (which may request your password)...\u001b[0m\n",
            "\u001b[1;34m==>\u001b[1;39m This script will install:\u001b[0m\n",
            "/home/linuxbrew/.linuxbrew/bin/brew\n",
            "/home/linuxbrew/.linuxbrew/share/doc/homebrew\n",
            "/home/linuxbrew/.linuxbrew/share/man/man1/brew.1\n",
            "/home/linuxbrew/.linuxbrew/share/zsh/site-functions/_brew\n",
            "/home/linuxbrew/.linuxbrew/etc/bash_completion.d/brew\n",
            "/home/linuxbrew/.linuxbrew/Homebrew\n",
            "\u001b[1;34m==>\u001b[1;39m /bin/chown -R root:root /home/linuxbrew/.linuxbrew/Homebrew\u001b[0m\n",
            "\u001b[1;34m==>\u001b[1;39m Downloading and installing Homebrew...\u001b[0m\n",
            "\u001b[34m==>\u001b[0m \u001b[1mUpdating Homebrew...\u001b[0m\n",
            "\u001b[1;31mWarning\u001b[0m: /home/linuxbrew/.linuxbrew/bin is not in your PATH.\n",
            "  Instructions on how to configure your shell for Homebrew\n",
            "  can be found in the 'Next steps' section below.\n",
            "\u001b[1;34m==>\u001b[1;39m Installation successful!\u001b[0m\n",
            "\n",
            "\u0007\u001b[1;34m==>\u001b[1;39m Homebrew has enabled anonymous aggregate formulae and cask analytics.\u001b[0m\n",
            "\u001b[1;39mRead the analytics documentation (and how to opt-out) here:\n",
            "  \u001b[4;39mhttps://docs.brew.sh/Analytics\u001b[0m\n",
            "No analytics data has been sent yet (nor will any be during this \u001b[1;39minstall\u001b[0m run).\n",
            "\n",
            "\u001b[1;34m==>\u001b[1;39m Homebrew is run entirely by unpaid volunteers. Please consider donating:\u001b[0m\n",
            "  \u001b[4;39mhttps://github.com/Homebrew/brew#donations\u001b[0m\n",
            "\n",
            "\u001b[1;34m==>\u001b[1;39m Next steps:\u001b[0m\n",
            "- Run this command in your terminal to add Homebrew to your \u001b[1;39mPATH\u001b[0m:\n",
            "    eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"\n",
            "- Install Homebrew's dependencies if you have sudo access:\n",
            "    sudo apt-get install build-essential\n",
            "  For more information, see:\n",
            "    \u001b[4;39mhttps://docs.brew.sh/Homebrew-on-Linux\u001b[0m\n",
            "- We recommend that you install GCC:\n",
            "    brew install gcc\n",
            "- Run \u001b[1;39mbrew help\u001b[0m to get started\n",
            "- Further documentation:\n",
            "    \u001b[4;39mhttps://docs.brew.sh\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!yes Y | /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gTzweLv-pmKW"
      },
      "outputs": [],
      "source": [
        "!echo >> /root/.bashrc\n",
        "!echo 'eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"' >> /root/.bashrc\n",
        "!eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuVwWsJIpwnr",
        "outputId": "57bfe420-b572-4e92-eb18-50bd6645c959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWarning:\u001b[0m gh 2.62.0 is already installed and up-to-date.\n",
            "To reinstall 2.62.0, run:\n",
            "  brew reinstall gh\n"
          ]
        }
      ],
      "source": [
        "!/home/linuxbrew/.linuxbrew/bin/brew install gh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugx4y-WyfE8x",
        "outputId": "5a4d1f14-445a-43fb-9f44-4c35f4eb76cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[0;33m!\u001b[0m First copy your one-time code: \u001b[0;1;39m02C9-F263\u001b[0m\n",
            "\u001b[0;1;39mOpen this URL\u001b[0m to continue in your web browser: https://github.com/login/device\n",
            "\u001b[0;32m✓\u001b[0m Authentication complete.\n",
            "\u001b[0;33m!\u001b[0m Authentication credentials saved in plain text\n",
            "\u001b[0;32m✓\u001b[0m Logged in as \u001b[0;1;39mjoshiarnav\u001b[0m\n",
            "\u001b[0;33m!\u001b[0m You were already logged in to this account\n"
          ]
        }
      ],
      "source": [
        "!yes Y | /home/linuxbrew/.linuxbrew/Cellar/gh/2.62.0/bin/gh auth login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x-CSyNRfsZEZ"
      },
      "outputs": [],
      "source": [
        "# !git config --global user.name \"joshiarnav\"\n",
        "# !git config --global user.email \"joshi.arnav.a@gmail.com\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "noV86B9Huqb_"
      },
      "outputs": [],
      "source": [
        "# !git clone https://username:PAT_token(generate_one_in_github_developer_settings)/joshiarnav/6158_final_project.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 6158_final_project/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRzyekM-41Qk",
        "outputId": "a6e9df9f-a959-407f-9f00-523962683a1f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/CS 6158/CS6158 Research Project/src/6158_final_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufI4IyEty-YI",
        "outputId": "c0c271e4-06a8-4c04-810e-a825d2cbfb85"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  33% (1/3)\rUnpacking objects:  66% (2/3)\rUnpacking objects: 100% (3/3)\rUnpacking objects: 100% (3/3), 370 bytes | 7.00 KiB/s, done.\n",
            "From https://github.com/joshiarnav/6158_final_project\n",
            "   0f5e785..75178d4  main       -> origin/main\n",
            "Updating 0f5e785..75178d4\n",
            "Fast-forward\n",
            " modelUtils.py | 6 \u001b[32m++++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 4 insertions(+), 2 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8zJxpoKyy5A",
        "outputId": "a66ac61a-0b58-45a3-cf00-842ee3aa22d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.46.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.13.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.4.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.5.2)\n",
            "Requirement already satisfied: huggingface_hub[cli] in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.26.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->-r requirements.txt (line 1)) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (0.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft->-r requirements.txt (line 3)) (1.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 7)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 7)) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: InquirerPy==0.3.4 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]->-r requirements.txt (line 9)) (0.3.4)\n",
            "Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]->-r requirements.txt (line 9)) (0.3.4)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]->-r requirements.txt (line 9)) (3.0.48)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]->-r requirements.txt (line 9)) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y tensorflow-cpu\n",
        "# !pip install tensorflow"
      ],
      "metadata": {
        "id": "yte57kZTJHQe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow==2.12.0\n",
        "# !pip install tf_keras==2.12.0 --no-deps"
      ],
      "metadata": {
        "id": "cMTMURmaMOrn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HZckP2UwcU3D"
      },
      "outputs": [],
      "source": [
        "from modelUtils import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from modelUtils import prepareMemoryDataset"
      ],
      "metadata": {
        "id": "-TKPubvaQTYi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lxR9kWZNcU3E"
      },
      "outputs": [],
      "source": [
        "tokenizer, model = loadTokenizerAndModel(\"meta-llama/Llama-3.2-1B\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "M-puDbX83f_2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rzkP54hncU3F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "bf4a8fc98df04e62b4bada6cfef03252",
            "42b2be32010c4ed9bd00e49817251f59",
            "b9b74f4f80414054b00c48becdbc7d6e",
            "78089d3046c442aab80d19305ea83f09",
            "01d19a1ab1934f5caf313efc3509a3f5",
            "e185d149be27449aaffc0a4dafcba9bb",
            "edf4781a51444d3daa93ae852a500387",
            "5709e4419b46493895b25f75902c98cd",
            "bb8418e17799497c93a69e9d23636ca2",
            "aac7ff8a95c646089d310fa715c5e441",
            "eb635866886943a9bcbf4aa6186ff525",
            "a619b2c8d416447880262fd79ff8e66b",
            "56b075ed2c554d8f8acb441776447fda",
            "e531ea4f9a864609b3cb00f68b5546e7",
            "24f79dcf49654c8f8cd33e881e711daa",
            "1481cc9b6896464b8c5064368e0ea09e",
            "9109c8fe80e74ee987b0a18f72d74ba4",
            "daf4121a586b461ebd40c7a147a2c63b",
            "888d9568d50344c78f70375fbccbec3c",
            "6cf7243ea46a41099f44dcc7042a2ff3",
            "a7c97bd94f574c61b3fea569f8b355b3",
            "88551b7fd9674ea8af47a530c43eb233",
            "3f5405f2aa7740c7b1935e6e8ee65d92",
            "3162cdc1289f410aa1a5d48bf6a86156",
            "860af43f3794425e8ed384b83f7d8b79",
            "e7f6db0fd22341b79da0d62be63ebff7",
            "d6fa0bae33b04972a49a6e6b94dbc102",
            "5ddcb05e4d80425f8612f01f80be0374",
            "86953d7f6aa14e1695debc01edfdb71b",
            "faf7abc5f6cf49ed869467ca141982b4",
            "5bed1b43be524dfab180ef1ae274908b",
            "44056bfce3cf47968f7f81320f73e946",
            "5e8042fbc54c40acab6be32238eaeb71",
            "44918da3e5874238b664a03ed0404798",
            "a7f1db956da7420dbd73f6c2b69acb4b",
            "3e7206fdcc5f49f2922d50d714e4f1c8",
            "635650efd6634d7295af33419edc7b0d",
            "11cdf58f8dd34cfd98e8a570ce7e8d34",
            "240bf1845a8b48f3a7a2e503a7dec027",
            "0452fd6249cd498ca1bc6b3f124c3b14",
            "befda373881e489680d7450ddf8fdb77",
            "1e4a3a95a13d417aa2b6a87de1a34644",
            "3e96aa98e1174cd990097b48723307f4",
            "4cda2725820e49aebcc7e4bb4657ef05",
            "fe73ec2d01ab4ceca0aeb92b6d8eaa7d",
            "321969f574ae4a64bbba6104654d515b",
            "9a12a22f6fa14a29aec2e351ebb8617b",
            "d7009d7a676d4437b53ed6e09c6a08c5",
            "46bf1c5eca9e458caf5db7a2edee4e5e",
            "f23bbd8e0d314817bdcf2345f29234ac",
            "2bd44ca625574c8f8df461f7ee6cc18c",
            "e120cdb406a0491d8d5f7814eb131f32",
            "f320d8024e27465cbc41dd5597f2804d",
            "c5ea9465689e45ddb327b57472687267",
            "da3145c5105144f388c362c2a6987f9e",
            "6451041189044413b8c08d307435766b",
            "ce1b317345df48f1839f51bf12a94521",
            "ef56828524c74e96a64fe12575fd6816",
            "7135afea2e444873b9b5f84f9e99c78d",
            "1f37c6eaaf894019b499bffdce5f42dd",
            "5cdaf3fcf3a04a71be37885298218fea",
            "3bbfde88f1604e62bd59afc5d5907da3",
            "824365f08e4543b3b30ed9ab2309d8d5",
            "eacf93bd91e64fbea3365a69fe67b458",
            "abca4adaaa5248479416a519be551ee7",
            "6d7dc0e5845042e9844129cf715a1a3b",
            "db35c54fa2af4cc58c9659e2e4355547",
            "4e2d8b3361124a9aa1f1a7a14f6f749a",
            "6554afe8c5164e4bbc7f2b22f9a611ad",
            "2adc01d935af40f7bfab9d1545ecd6cc",
            "47c7ebbd78bf47128d11f701a329b26f",
            "5cb8e0d984014c51bf829b2c3b4e9cc4",
            "d8411fa689e94926a784ac7245f6582a",
            "c6e8bdf568f047e1a963c163eeb8a954",
            "2533e059ed6044c19d5be3361d0c7889",
            "cff264372ac343ac868200d9411c2c32",
            "ce60e917e46a429287b89a20353150e0",
            "51ab391727db43c89b3f2cff1ecf425c",
            "2cf7939826e34b0b9ec77bdd47aa4688",
            "b16ececf7ee94d26a58aa539cc10aaed",
            "55a4b95f8c734f05aaff75233a96a381",
            "a6579822db994199be9d8539636ef3ad",
            "4d391e8eca344fa985fa3c6429d5b2a3",
            "867f9a49680541e982fb86833f6a1bfb",
            "366e8e93ca254cc0976c2fb5b8612a9b",
            "32a9cd52a9c341e3ac0b7b0266868dc5",
            "3ba81dc9e7234b39b6d6acb101ac81ef",
            "68d24611e73a4f63991c53e28b3d91a9"
          ]
        },
        "outputId": "3417388e-3ac4-4fd3-b57b-92f6a1740a54"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf4a8fc98df04e62b4bada6cfef03252"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a619b2c8d416447880262fd79ff8e66b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/40 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f5405f2aa7740c7b1935e6e8ee65d92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/11 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44918da3e5874238b664a03ed0404798"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe73ec2d01ab4ceca0aeb92b6d8eaa7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6451041189044413b8c08d307435766b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db35c54fa2af4cc58c9659e2e4355547"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51ab391727db43c89b3f2cff1ecf425c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_data, test_data = prepareMemoryDataset(tokenizer, save_path='../datasets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8xp625ZRcU3F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae933e0-1444-4e17-aa34-7e75ab3cacfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/gdrive/MyDrive/CS 6158/CS6158 Research Project/src/6158_final_project/modelUtils.py:184: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
          ]
        }
      ],
      "source": [
        "trainer = createTrainer(model, train_data, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9puW5TfIKkI",
        "outputId": "0d9bdf29-8b8a-4264-c55b-251c708921f7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PzYprQyicU3F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "e6f29194-d5e0-4e45-c895-34fa0aa73f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 09:39, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.679500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.758000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.565500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.538800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.526100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.503700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=600, training_loss=0.7619461059570313, metrics={'train_runtime': 582.2046, 'train_samples_per_second': 1.031, 'train_steps_per_second': 1.031, 'total_flos': 7179522696806400.0, 'train_loss': 0.7619461059570313, 'epoch': 15.0})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"nofuneval_memory_model\")"
      ],
      "metadata": {
        "id": "C811GtW034Zx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "3uG_UFBMXUmx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateOutputs(model, test_data, tokenizer, name):\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "    for i in range(len(test_data)):\n",
        "        input_ids = torch.tensor(test_data[i]['input_ids']).to(device)\n",
        "        attention_mask = test_data[i]['attention_mask'].to(device)\n",
        "        output = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=2048, num_beams=4, early_stopping=True)\n",
        "        outputs.append(tokenizer.decode(output[0], skip_special_tokens=True))\n",
        "    with open(f\"../outputs/{name}_outputs.txt\", \"w\") as f:\n",
        "        for output in outputs:\n",
        "            f.write(f\"{output}\\n\")"
      ],
      "metadata": {
        "id": "gg4IXU2VWRo2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generateOutputs(model, test_data, tokenizer, \"nofuneval_memory_model\")"
      ],
      "metadata": {
        "id": "eBKi4nb8W8zj",
        "outputId": "2a09a9b3-11b4-4150-aa36-c0d1b0b05439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'to'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-cac69147fb2b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerateOutputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nofuneval_memory_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-f19e82a35703>\u001b[0m in \u001b[0;36mgenerateOutputs\u001b[0;34m(model, test_data, tokenizer, name)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)"
      ],
      "metadata": {
        "id": "KWCmIhjtW_Ds"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_data)):\n",
        "  print(pipe(test_data[i]['input_text']))"
      ],
      "metadata": {
        "id": "_RZHGrGDXjOn",
        "outputId": "d0a74b38-5788-443a-b503-58982922bc07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input length of input_ids is 1038, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-c248a22746bc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     def preprocess(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             )\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1207\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generation_config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2066\u001b[0m             \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_logits_to_keep\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2068\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_generated_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_default_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0;31m# 7. Prepare the cache.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_validate_generated_length\u001b[0;34m(self, generation_config, input_ids_length, has_default_max_length)\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_ids_length\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0minput_ids_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"decoder_input_ids\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1384\u001b[0m                 \u001b[0;34mf\"Input length of {input_ids_string} is {input_ids_length}, but `max_length` is set to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m                 \u001b[0;34mf\" {generation_config.max_length}. This can lead to unexpected behavior. You should consider\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input length of input_ids is 1038, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipe(\"def push_tensor_to_gpu(tensors):\\n   for tensor in tensors:\\n.   \\n\\n\\n        tensor.set_device(torch.\"))"
      ],
      "metadata": {
        "id": "PnXugAYUXvcx",
        "outputId": "13e95e22-c9ea-4772-a8ae-a4086cab951b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input length of input_ids is 24, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-1a3b1b93cc7a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"def push_tensor_to_gpu(tensors):\\n   for tensor in tensors:\\n.   \\n\\n\\n        tensor.set_device(torch.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     def preprocess(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             )\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1207\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generation_config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2066\u001b[0m             \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_logits_to_keep\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2068\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_generated_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_default_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0;31m# 7. Prepare the cache.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_validate_generated_length\u001b[0;34m(self, generation_config, input_ids_length, has_default_max_length)\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_ids_length\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0minput_ids_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"decoder_input_ids\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1384\u001b[0m                 \u001b[0;34mf\"Input length of {input_ids_string} is {input_ids_length}, but `max_length` is set to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m                 \u001b[0;34mf\" {generation_config.max_length}. This can lead to unexpected behavior. You should consider\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input length of input_ids is 24, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data)"
      ],
      "metadata": {
        "id": "jpMzz9MgYPgo",
        "outputId": "7f40d235-acb4-402d-f997-57333e26a021",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['non_functional_requirement', 'commit', 'commit_message', 'source_code', 'target_code', 'pl', 'chain_of_thought', 'one_shot', 'base_prompt', 'coding_concepts', 'classification_left_prompt', 'classification_left_label', 'classification_right_prompt', 'classification_right_label', 'input_text', 'output_text', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 11\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[0])"
      ],
      "metadata": {
        "id": "GMxkHFQuZBnM",
        "outputId": "416e78bd-427d-4548-a4f5-98fb642f4874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'non_functional_requirement': 'energy', 'commit': 'https://github.com/plokhotnyuk/actors/commit/8d96e0e6fd0bc1df605908ed711346171b662810', 'commit_message': 'improved backoff to be more energy efficient by parking waiting threads until submitting of new tasks', 'source_code': 'package com.github.plokhotnyuk.actors\\n\\nimport java.util.concurrent._\\nimport java.util.concurrent.atomic.{AtomicReference, AtomicInteger}\\nimport java.lang.InterruptedException\\nimport scala.annotation.tailrec\\nimport java.util.concurrent.locks.LockSupport\\n\\n/**\\n * A high performance implementation of thread pool with fixed number of threads.\\n *\\n * Implementation of task queue based on non-intrusive MPSC node-based queue, described by Dmitriy Vyukov:\\n * http://www.1024cores.net/home/lock-free-algorithms/queues/non-intrusive-mpsc-node-based-queue\\n *\\n * @param threadCount a number of worker threads in pool\\n * @param threadFactory a factory to be used to build worker threads\\n * @param handler the handler for internal worker threads that will be called\\n *                in case of unrecoverable errors encountered while executing tasks.\\n */\\nclass FastThreadPoolExecutor(threadCount: Int = Runtime.getRuntime.availableProcessors(),\\n                             threadFactory: ThreadFactory = new ThreadFactory() {\\n                               def newThread(r: Runnable): Thread = new Thread(r) {\\n                                 setDaemon(true) // is it good reason: \"to avoid stalls on app end in case of missed shutdown call\"?\\n                               }\\n                             },\\n                             handler: Thread.UncaughtExceptionHandler = new Thread.UncaughtExceptionHandler() {\\n                               def uncaughtException(t: Thread, e: Throwable) {\\n                                 e.printStackTrace() // is it safe default implementation?\\n                               }\\n                             }) extends AbstractExecutorService {\\n  private val closing = new AtomicInteger(0)\\n  private val taskHead = new AtomicReference[TaskNode](new TaskNode())\\n  private val taskTail = new AtomicReference[TaskNode](taskHead.get)\\n  private val terminations = new CountDownLatch(threadCount)\\n  private val threads = {\\n    val tf = threadFactory // to avoid creating of field for the threadFactory constructor param\\n    val c = closing  // to avoid long field names\\n    val tt = taskTail\\n    val h = handler\\n    val t = terminations\\n    (1 to threadCount).map(_ => tf.newThread(new Worker(c, tt, h, t)))\\n  }\\n  threads.foreach(_.start())\\n\\n  def shutdown() {\\n    shutdownNow()\\n    awaitTermination(0, TimeUnit.MILLISECONDS)\\n  }\\n\\n  def shutdownNow(): java.util.List[Runnable] = {\\n    closing.set(1)\\n    threads.filter(_ ne Thread.currentThread()).foreach(_.interrupt()) // don\\'t interrupt worker thread due call in task\\n    drainRemainingTasks(new java.util.LinkedList[Runnable]())\\n  }\\n\\n  def isShutdown: Boolean = closing.get != 0\\n\\n  def isTerminated: Boolean = terminations.getCount == 0\\n\\n  def awaitTermination(timeout: Long, unit: TimeUnit): Boolean = {\\n    if (threads.exists(_ eq Thread.currentThread())) terminations.countDown() // don\\'t hang up due call in task\\n    terminations.await(timeout, unit)\\n  }\\n\\n  def execute(task: Runnable) {\\n    if (isShutdown) throw new IllegalStateException(\"Cannot execute in terminating/shutdown state\")\\n    if (task eq null) throw new NullPointerException\\n    val n = new TaskNode(task)\\n    taskHead.getAndSet(n).lazySet(n)\\n  }\\n\\n  @tailrec\\n  private def drainRemainingTasks(ts: java.util.List[Runnable]): java.util.List[Runnable] = {\\n    val tn = taskTail.get\\n    val n = tn.get\\n    if ((n ne null) && taskTail.compareAndSet(tn, n)) {\\n      ts.add(n.task)\\n      drainRemainingTasks(ts)\\n    } else ts\\n  }\\n}\\n\\nprivate class Worker(closing: AtomicInteger, taskTail: AtomicReference[TaskNode],\\n                     handler: Thread.UncaughtExceptionHandler, terminations: CountDownLatch) extends Runnable {\\n  def run() {\\n    try {\\n      doWork()\\n    } finally {\\n      terminations.countDown()\\n    }\\n  }\\n\\n  private def doWork() {\\n    while (closing.get == 0) {\\n      try {\\n        val tn = taskTail.get\\n        val n = tn.get\\n        if (n eq null) backOff()\\n        else if (taskTail.compareAndSet(tn, n)) n.run()\\n      } catch {\\n        case ex: InterruptedException => return\\n        case ex: Throwable => onError(ex)\\n      }\\n    }\\n  }\\n\\n  private def backOff() {\\n    LockSupport.parkNanos(100)\\n  }\\n\\n  private def onError(ex: Throwable) {\\n    handler.uncaughtException(Thread.currentThread(), ex)\\n  }\\n}\\n\\nprivate class TaskNode(var task: Runnable = null) extends AtomicReference[TaskNode] {\\n  def run() {\\n    task.run()\\n    task = null // to avoid holding of task reference when queue is empty\\n  }\\n}', 'target_code': 'package com.github.plokhotnyuk.actors\\n\\nimport java.util.concurrent._\\nimport java.util.concurrent.atomic.{AtomicLong, AtomicReference, AtomicInteger}\\nimport java.lang.InterruptedException\\nimport scala.annotation.tailrec\\nimport java.util.concurrent.locks.LockSupport\\n\\n/**\\n * A high performance implementation of thread pool with fixed number of threads.\\n *\\n * Implementation of task queue based on non-intrusive MPSC node-based queue, described by Dmitriy Vyukov:\\n * http://www.1024cores.net/home/lock-free-algorithms/queues/non-intrusive-mpsc-node-based-queue\\n *\\n * @param threadCount a number of worker threads in pool\\n * @param threadFactory a factory to be used to build worker threads\\n * @param handler the handler for internal worker threads that will be called\\n *                in case of unrecoverable errors encountered while executing tasks.\\n */\\nclass FastThreadPoolExecutor(threadCount: Int = Runtime.getRuntime.availableProcessors(),\\n                             threadFactory: ThreadFactory = new ThreadFactory() {\\n                               def newThread(r: Runnable): Thread = new Thread(r) {\\n                                 setDaemon(true) // is it good reason: \"to avoid stalls on app end in case of missed shutdown call\"?\\n                               }\\n                             },\\n                             handler: Thread.UncaughtExceptionHandler = new Thread.UncaughtExceptionHandler() {\\n                               def uncaughtException(t: Thread, e: Throwable) {\\n                                 e.printStackTrace() // is it safe default implementation?\\n                               }\\n                             }) extends AbstractExecutorService {\\n  private val closing = new AtomicInteger(0)\\n  private val taskHead = new AtomicReference[TaskNode](new TaskNode())\\n  private val taskTail = new AtomicReference[TaskNode](taskHead.get)\\n  private val waitingThreads = new ConcurrentLinkedQueue[Thread]()\\n  private val terminations = new CountDownLatch(threadCount)\\n  private val threads = {\\n    val tf = threadFactory // to avoid creating of field for the threadFactory constructor param\\n    val c = closing  // to avoid long field names\\n    val tt = taskTail\\n    val h = handler\\n    val wt = waitingThreads\\n    val t = terminations\\n    (1 to threadCount).map(_ => tf.newThread(new Worker(c, tt, h, wt, t)))\\n  }\\n  threads.foreach(_.start())\\n\\n  def shutdown() {\\n    shutdownNow()\\n    awaitTermination(0, TimeUnit.MILLISECONDS)\\n  }\\n\\n  def shutdownNow(): java.util.List[Runnable] = {\\n    closing.set(1)\\n    threads.filter(_ ne Thread.currentThread()).foreach(_.interrupt()) // don\\'t interrupt worker thread due call in task\\n    drainRemainingTasks(new java.util.LinkedList[Runnable]())\\n  }\\n\\n  def isShutdown: Boolean = closing.get != 0\\n\\n  def isTerminated: Boolean = terminations.getCount == 0\\n\\n  def awaitTermination(timeout: Long, unit: TimeUnit): Boolean = {\\n    if (threads.exists(_ eq Thread.currentThread())) terminations.countDown() // don\\'t hang up due call in task\\n    terminations.await(timeout, unit)\\n  }\\n\\n  def execute(task: Runnable) {\\n    if (isShutdown) throw new IllegalStateException(\"Cannot execute in terminating/shutdown state\")\\n    if (task eq null) throw new NullPointerException\\n    val n = new TaskNode(task)\\n    taskHead.getAndSet(n).lazySet(n)\\n    LockSupport.unpark(waitingThreads.poll())\\n  }\\n\\n  @tailrec\\n  private def drainRemainingTasks(ts: java.util.List[Runnable]): java.util.List[Runnable] = {\\n    val tn = taskTail.get\\n    val n = tn.get\\n    if ((n ne null) && taskTail.compareAndSet(tn, n)) {\\n      ts.add(n.task)\\n      drainRemainingTasks(ts)\\n    } else ts\\n  }\\n}\\n\\nprivate class Worker(closing: AtomicInteger, taskTail: AtomicReference[TaskNode],\\n                     handler: Thread.UncaughtExceptionHandler, waitingThreads: ConcurrentLinkedQueue[Thread],\\n                     terminations: CountDownLatch) extends Runnable {\\n  private var backOffs = 0\\n\\n  def run() {\\n    try {\\n      doWork()\\n    } finally {\\n      terminations.countDown()\\n    }\\n  }\\n\\n  private def doWork() {\\n    while (closing.get == 0) {\\n      try {\\n        val tn = taskTail.get\\n        val n = tn.get\\n        if (n eq null) backOff()\\n        else if (taskTail.compareAndSet(tn, n)) execute(n)\\n      } catch {\\n        case ex: InterruptedException => return\\n        case ex: Throwable => onError(ex)\\n      }\\n    }\\n  }\\n\\n  private def execute(n: TaskNode) {\\n    n.task.run()\\n    n.task = null // to avoid holding of task reference when queue is empty\\n    backOffs = 0\\n  }\\n\\n  private def backOff() {\\n    backOffs += 1\\n    if (backOffs < 2) Thread.`yield`()\\n    else if (backOffs < 4) LockSupport.parkNanos(1L)\\n    else {\\n      waitingThreads.offer(Thread.currentThread())\\n      LockSupport.park(this)\\n    }\\n  }\\n\\n  private def onError(ex: Throwable) {\\n    handler.uncaughtException(Thread.currentThread(), ex)\\n  }\\n}\\n\\nprivate class TaskNode(var task: Runnable = null) extends AtomicReference[TaskNode]', 'pl': 'Scala', 'chain_of_thought': 'Below is an instruction that describes a task along with an example. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nRewrite the given JavaScript program to optimize and improve the energy usage. Write the entire code and no other text.\\n```javascript\\nvar keen = require(\\'keen.io\\');\\nvar SensorTag = require(\\'sensortag\\');\\n\\nvar keen = keen.configure({\\n \\xa0 \\xa0projectId: process.env.keen_io_projectId,\\n \\xa0 \\xa0writeKey: process.env.keen_io_writeKey\\n});\\n\\nvar uuid = process.env.sensortag_uuid;\\n\\nfunction send_to_keenio(temperature,humidity,uuid) {\\n \\xa0 \\xa0console.log(uuid + \\'\\\\ttemperature = %d °C\\', temperature);\\n \\xa0 \\xa0console.log(uuid + \\'\\\\thumidity = %d %\\', humidity);\\n\\n \\xa0 \\xa0var eventdata = {};\\n \\xa0 \\xa0eventdata[\"SensorTag \" + uuid] = [\\n\\t{\\n \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\"temperature\": temperature,\\n \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\"humidity\": humidity\\n \\xa0 \\xa0 \\xa0 \\xa0}\\n \\xa0 \\xa0];\\n \\xa0 \\xa0keen.addEvents(eventdata, function(err, res) {\\n\\tif (err) {\\n\\t \\xa0 \\xa0console.log(\"Error sending to keen \" + err + res);\\n\\t}\\n \\xa0 \\xa0});\\n};\\n\\nconsole.log(\\'Init, discover uuids \\' + uuid);\\nSensorTag.discover(function(sensorTag) {\\n \\xa0 \\xa0var uuid = sensorTag.uuid;\\n \\xa0 \\xa0console.log(uuid + \\' Discovered\\');\\n \\xa0 \\xa0sensorTag.connect(function() {\\n\\tconsole.log(uuid + \\' Connected\\');\\n\\tsensorTag.discoverServicesAndCharacteristics(function() {\\n\\t \\xa0 \\xa0console.log(uuid + \\' DiscoverServicesAndCharacteristics\\');\\n \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0sensorTag.enableHumidity(function() {\\n\\t\\tconsole.log(uuid + \\' Humidity sensor enabled\\');\\n\\t\\tsensorTag.on(\\'humidityChange\\', function(temperature, humidity) {\\n\\t\\t \\xa0 \\xa0send_to_keenio(temperature,humidity,uuid);\\n\\t\\t});\\n\\t\\t\\n\\t\\tsensorTag.notifyHumidity(function() {\\n\\t\\t \\xa0 \\xa0console.log(uuid + \\'Humidity notifications enabled\\');\\n\\t\\t});\\n\\t \\xa0 \\xa0});\\n\\t});\\n \\xa0 \\xa0});\\n}, uuid);\\n\\n\\n```\\n\\n### Thought:\\nThe javascript code continuously polls for and sends the temperature and humidity sensor readings. This is potentially inefficient in terms of power usage. One way of optimizing the code is to check and notify the sensor readings at certain intervals, and disable the sensors at other times. To do this, we should first determine the measurement intervals, declare it is a variable that can be tweaked later if needed. We can use the \\'setInterval\\' function to enable the sensor at determined frequency. In the main code (discover method call), we first check and log the sensor values on the \\'humidityChange\\' event, send the values using the defined \\'send_to_keenio\\' function, and disable the sensors at the end of the event. The resulting code optimized for power savings is as follows.\\n\\n\\n### Response:\\n```javascript\\n \\n// 20 seconds in milliseconds\\nvar measurementIntervalMs = 20000;\\n\\nvar keen = require(\\'keen.io\\');\\nvar SensorTag = require(\\'sensortag\\');\\n\\nvar keen = keen.configure({\\n \\xa0 \\xa0projectId: process.env.keen_io_projectId,\\n \\xa0 \\xa0writeKey: process.env.keen_io_writeKey\\n});\\n\\nvar uuid = process.env.sensortag_uuid;\\n\\nfunction send_to_keenio(temperature,humidity,uuid) {\\n \\xa0 \\xa0console.log(uuid + \\' \\\\ttemperature = %d °C\\', temperature);\\n \\xa0 \\xa0console.log(uuid + \\' \\\\thumidity = %d %\\', humidity);\\n\\n \\xa0 \\xa0var eventdata = {};\\n \\xa0 \\xa0eventdata[\"SensorTag \" + uuid] = [\\n\\t{\\n \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\"temperature\": temperature,\\n \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\"humidity\": humidity\\n \\xa0 \\xa0 \\xa0 \\xa0}\\n \\xa0 \\xa0];\\n \\xa0 \\xa0keen.addEvents(eventdata, function(err, res) {\\n\\tif (err) {\\n\\t \\xa0 \\xa0console.log(\"Error sending to keen \" + err + res);\\n\\t}\\n \\xa0 \\xa0});\\n};\\n\\nconsole.log(\\'Init, discover uuids \\' + uuid);\\nSensorTag.discover(function(sensorTag) {\\n \\xa0 \\xa0var uuid = sensorTag.uuid;\\n \\xa0 \\xa0console.log(uuid + \\' Discovered\\');\\n \\xa0 \\xa0sensorTag.connect(function() {\\n\\tconsole.log(uuid + \\' Connected\\');\\n\\tsensorTag.discoverServicesAndCharacteristics(function() {\\n\\t \\xa0 \\xa0console.log(uuid + \\' DiscoverServicesAndCharacteristics\\');\\n\\t \\xa0 \\xa0sensorTag.on(\\'humidityChange\\', function(temperature, humidity) {\\n\\t\\t// Ignore readings of a disabled sensor\\n\\t\\tif (temperature == -46.85 && humidity == -6) {\\n\\t\\t \\xa0 \\xa0return;\\n\\t\\t}\\n\\t\\tvar temp = temperature.toFixed(2);\\n\\t\\tvar hum = humidity.toFixed(2);\\n\\t\\tsensorTag.disableHumidity(function() {\\n\\t\\t \\xa0 \\xa0console.log(uuid + \\' Got reading, humidity sensor disabled for \\' + measurementIntervalMs + \\' ms\\');\\n\\t\\t});\\n\\t\\tsend_to_keenio(temp,hum,uuid);\\n\\t \\xa0 \\xa0});\\n\\t \\xa0 \\xa0\\n\\t \\xa0 \\xa0setInterval(function() {\\n\\t\\tsensorTag.enableHumidity(function() {\\n\\t\\t \\xa0 \\xa0console.log(uuid + \\' Humidity sensor enabled to get the next reading\\');\\n\\t\\t});\\n\\t \\xa0 \\xa0}, measurementIntervalMs);\\n\\t \\xa0 \\xa0\\n\\t \\xa0 \\xa0sensorTag.notifyHumidity(function() {\\n\\t\\tconsole.log(uuid + \\' Humidity notifications enabled\\');\\n\\t \\xa0 \\xa0});\\n\\t});\\n \\xa0 \\xa0});\\n}, uuid);\\n\\n\\n```\\n\\n### Instruction:\\nRewrite the given scala program to optimize and improve the energy usage. Write the entire code and no other text in the response.\\n```scala\\npackage com.github.plokhotnyuk.actors\\n\\nimport java.util.concurrent._\\nimport java.util.concurrent.atomic.{AtomicReference, AtomicInteger}\\nimport java.lang.InterruptedException\\nimport scala.annotation.tailrec\\nimport java.util.concurrent.locks.LockSupport\\n\\n/**\\n * A high performance implementation of thread pool with fixed number of threads.\\n *\\n * Implementation of task queue based on non-intrusive MPSC node-based queue, described by Dmitriy Vyukov:\\n * http://www.1024cores.net/home/lock-free-algorithms/queues/non-intrusive-mpsc-node-based-queue\\n *\\n * @param threadCount a number of worker threads in pool\\n * @param threadFactory a factory to be used to build worker threads\\n * @param handler the handler for internal worker threads that will be called\\n *                in case of unrecoverable errors encountered while executing tasks.\\n */\\nclass FastThreadPoolExecutor(threadCount: Int = Runtime.getRuntime.availableProcessors(),\\n                             threadFactory: ThreadFactory = new ThreadFactory() {\\n                               def newThread(r: Runnable): Thread = new Thread(r) {\\n                                 setDaemon(true) // is it good reason: \"to avoid stalls on app end in case of missed shutdown call\"?\\n                               }\\n                             },\\n                             handler: Thread.UncaughtExceptionHandler = new Thread.UncaughtExceptionHandler() {\\n                               def uncaughtException(t: Thread, e: Throwable) {\\n                                 e.printStackTrace() // is it safe default implementation?\\n                               }\\n                             }) extends AbstractExecutorService {\\n  private val closing = new AtomicInteger(0)\\n  private val taskHead = new AtomicReference[TaskNode](new TaskNode())\\n  private val taskTail = new AtomicReference[TaskNode](taskHead.get)\\n  private val terminations = new CountDownLatch(threadCount)\\n  private val threads = {\\n    val tf = threadFactory // to avoid creating of field for the threadFactory constructor param\\n    val c = closing  // to avoid long field names\\n    val tt = taskTail\\n    val h = handler\\n    val t = terminations\\n    (1 to threadCount).map(_ => tf.newThread(new Worker(c, tt, h, t)))\\n  }\\n  threads.foreach(_.start())\\n\\n  def shutdown() {\\n    shutdownNow()\\n    awaitTermination(0, TimeUnit.MILLISECONDS)\\n  }\\n\\n  def shutdownNow(): java.util.List[Runnable] = {\\n    closing.set(1)\\n    threads.filter(_ ne Thread.currentThread()).foreach(_.interrupt()) // don\\'t interrupt worker thread due call in task\\n    drainRemainingTasks(new java.util.LinkedList[Runnable]())\\n  }\\n\\n  def isShutdown: Boolean = closing.get != 0\\n\\n  def isTerminated: Boolean = terminations.getCount == 0\\n\\n  def awaitTermination(timeout: Long, unit: TimeUnit): Boolean = {\\n    if (threads.exists(_ eq Thread.currentThread())) terminations.countDown() // don\\'t hang up due call in task\\n    terminations.await(timeout, unit)\\n  }\\n\\n  def execute(task: Runnable) {\\n    if (isShutdown) throw new IllegalStateException(\"Cannot execute in terminating/shutdown state\")\\n    if (task eq null) throw new NullPointerException\\n    val n = new TaskNode(task)\\n    taskHead.getAndSet(n).lazySet(n)\\n  }\\n\\n  @tailrec\\n  private def drainRemainingTasks(ts: java.util.List[Runnable]): java.util.List[Runnable] = {\\n    val tn = taskTail.get\\n    val n = tn.get\\n    if ((n ne null) && taskTail.compareAndSet(tn, n)) {\\n      ts.add(n.task)\\n      drainRemainingTasks(ts)\\n    } else ts\\n  }\\n}\\n\\nprivate class Worker(closing: AtomicInteger, taskTail: AtomicReference[TaskNode],\\n                     handler: Thread.UncaughtExceptionHandler, terminations: CountDownLatch) extends Runnable {\\n  def run() {\\n    try {\\n      doWork()\\n    } finally {\\n      terminations.countDown()\\n    }\\n  }\\n\\n  private def doWork() {\\n    while (closing.get == 0) {\\n      try {\\n        val tn = taskTail.get\\n        val n = tn.get\\n        if (n eq null) backOff()\\n        else if (taskTail.compareAndSet(tn, n)) n.run()\\n      } catch {\\n        case ex: InterruptedException => return\\n        case ex: Throwable => onError(ex)\\n      }\\n    }\\n  }\\n\\n  private def backOff() {\\n    LockSupport.parkNanos(100)\\n  }\\n\\n  private def onError(ex: Throwable) {\\n    handler.uncaughtException(Thread.currentThread(), ex)\\n  }\\n}\\n\\nprivate class TaskNode(var task: Runnable = null) extends AtomicReference[TaskNode] {\\n  def run() {\\n    task.run()\\n    task = null // to avoid holding of task reference when queue is empty\\n  }\\n}\\n```\\n\\n### Thought:\\n', 'one_shot': 'Below is an instruction that describes a task along with an example. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nRewrite the given JavaScript program to optimize and improve the energy usage. Write the entire code and no other text.\\n```javascript\\nvar keen = require(\\'keen.io\\');\\nvar SensorTag = require(\\'sensortag\\');\\n\\nvar keen = keen.configure({\\n \\xa0 \\xa0projectId: process.env.keen_io_projectId,\\n \\xa0 \\xa0writeKey: process.env.keen_io_writeKey\\n});\\n\\nvar uuid = process.env.sensortag_uuid;\\n\\nfunction send_to_keenio(temperature,humidity,uuid) {\\n \\xa0 \\xa0console.log(uuid + \\'\\\\ttemperature = %d °C\\', temperature);\\n \\xa0 \\xa0console.log(uuid + \\'\\\\thumidity = %d %\\', humidity);\\n\\n \\xa0 \\xa0var eventdata = {};\\n \\xa0 \\xa0eventdata[\"SensorTag \" + uuid] = [\\n\\t{\\n \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\"temperature\": temperature,\\n \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\"humidity\": humidity\\n \\xa0 \\xa0 \\xa0 \\xa0}\\n \\xa0 \\xa0];\\n \\xa0 \\xa0keen.addEvents(eventdata, function(err, res) {\\n\\tif (err) {\\n\\t \\xa0 \\xa0console.log(\"Error sending to keen \" + err + res);\\n\\t}\\n \\xa0 \\xa0});\\n};\\n\\nconsole.log(\\'Init, discover uuids \\' + uuid);\\nSensorTag.discover(function(sensorTag) {\\n \\xa0 \\xa0var uuid = sensorTag.uuid;\\n \\xa0 \\xa0console.log(uuid + \\' Discovered\\');\\n \\xa0 \\xa0sensorTag.connect(function() {\\n\\tconsole.log(uuid + \\' Connected\\');\\n\\tsensorTag.discoverServicesAndCharacteristics(function() {\\n\\t \\xa0 \\xa0console.log(uuid + \\' DiscoverServicesAndCharacteristics\\');\\n \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0sensorTag.enableHumidity(function() {\\n\\t\\tconsole.log(uuid + \\' Humidity sensor enabled\\');\\n\\t\\tsensorTag.on(\\'humidityChange\\', function(temperature, humidity) {\\n\\t\\t \\xa0 \\xa0send_to_keenio(temperature,humidity,uuid);\\n\\t\\t});\\n\\t\\t\\n\\t\\tsensorTag.notifyHumidity(function() {\\n\\t\\t \\xa0 \\xa0console.log(uuid + \\'Humidity notifications enabled\\');\\n\\t\\t});\\n\\t \\xa0 \\xa0});\\n\\t});\\n \\xa0 \\xa0});\\n}, uuid);\\n\\n\\n```\\n\\n### Response:\\n```javascript\\n \\n// 20 seconds in milliseconds\\nvar measurementIntervalMs = 20000;\\n\\nvar keen = require(\\'keen.io\\');\\nvar SensorTag = require(\\'sensortag\\');\\n\\nvar keen = keen.configure({\\n \\xa0 \\xa0projectId: process.env.keen_io_projectId,\\n \\xa0 \\xa0writeKey: process.env.keen_io_writeKey\\n});\\n\\nvar uuid = process.env.sensortag_uuid;\\n\\nfunction send_to_keenio(temperature,humidity,uuid) {\\n \\xa0 \\xa0console.log(uuid + \\' \\\\ttemperature = %d °C\\', temperature);\\n \\xa0 \\xa0console.log(uuid + \\' \\\\thumidity = %d %\\', humidity);\\n\\n \\xa0 \\xa0var eventdata = {};\\n \\xa0 \\xa0eventdata[\"SensorTag \" + uuid] = [\\n\\t{\\n \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\"temperature\": temperature,\\n \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\"humidity\": humidity\\n \\xa0 \\xa0 \\xa0 \\xa0}\\n \\xa0 \\xa0];\\n \\xa0 \\xa0keen.addEvents(eventdata, function(err, res) {\\n\\tif (err) {\\n\\t \\xa0 \\xa0console.log(\"Error sending to keen \" + err + res);\\n\\t}\\n \\xa0 \\xa0});\\n};\\n\\nconsole.log(\\'Init, discover uuids \\' + uuid);\\nSensorTag.discover(function(sensorTag) {\\n \\xa0 \\xa0var uuid = sensorTag.uuid;\\n \\xa0 \\xa0console.log(uuid + \\' Discovered\\');\\n \\xa0 \\xa0sensorTag.connect(function() {\\n\\tconsole.log(uuid + \\' Connected\\');\\n\\tsensorTag.discoverServicesAndCharacteristics(function() {\\n\\t \\xa0 \\xa0console.log(uuid + \\' DiscoverServicesAndCharacteristics\\');\\n\\t \\xa0 \\xa0sensorTag.on(\\'humidityChange\\', function(temperature, humidity) {\\n\\t\\t// Ignore readings of a disabled sensor\\n\\t\\tif (temperature == -46.85 && humidity == -6) {\\n\\t\\t \\xa0 \\xa0return;\\n\\t\\t}\\n\\t\\tvar temp = temperature.toFixed(2);\\n\\t\\tvar hum = humidity.toFixed(2);\\n\\t\\tsensorTag.disableHumidity(function() {\\n\\t\\t \\xa0 \\xa0console.log(uuid + \\' Got reading, humidity sensor disabled for \\' + measurementIntervalMs + \\' ms\\');\\n\\t\\t});\\n\\t\\tsend_to_keenio(temp,hum,uuid);\\n\\t \\xa0 \\xa0});\\n\\t \\xa0 \\xa0\\n\\t \\xa0 \\xa0setInterval(function() {\\n\\t\\tsensorTag.enableHumidity(function() {\\n\\t\\t \\xa0 \\xa0console.log(uuid + \\' Humidity sensor enabled to get the next reading\\');\\n\\t\\t});\\n\\t \\xa0 \\xa0}, measurementIntervalMs);\\n\\t \\xa0 \\xa0\\n\\t \\xa0 \\xa0sensorTag.notifyHumidity(function() {\\n\\t\\tconsole.log(uuid + \\' Humidity notifications enabled\\');\\n\\t \\xa0 \\xa0});\\n\\t});\\n \\xa0 \\xa0});\\n}, uuid);\\n\\n\\n```\\n\\n### Instruction:\\nRewrite the given scala program to optimize and improve the energy usage. Write the entire code and no other text in the response.\\n```scala\\npackage com.github.plokhotnyuk.actors\\n\\nimport java.util.concurrent._\\nimport java.util.concurrent.atomic.{AtomicReference, AtomicInteger}\\nimport java.lang.InterruptedException\\nimport scala.annotation.tailrec\\nimport java.util.concurrent.locks.LockSupport\\n\\n/**\\n * A high performance implementation of thread pool with fixed number of threads.\\n *\\n * Implementation of task queue based on non-intrusive MPSC node-based queue, described by Dmitriy Vyukov:\\n * http://www.1024cores.net/home/lock-free-algorithms/queues/non-intrusive-mpsc-node-based-queue\\n *\\n * @param threadCount a number of worker threads in pool\\n * @param threadFactory a factory to be used to build worker threads\\n * @param handler the handler for internal worker threads that will be called\\n *                in case of unrecoverable errors encountered while executing tasks.\\n */\\nclass FastThreadPoolExecutor(threadCount: Int = Runtime.getRuntime.availableProcessors(),\\n                             threadFactory: ThreadFactory = new ThreadFactory() {\\n                               def newThread(r: Runnable): Thread = new Thread(r) {\\n                                 setDaemon(true) // is it good reason: \"to avoid stalls on app end in case of missed shutdown call\"?\\n                               }\\n                             },\\n                             handler: Thread.UncaughtExceptionHandler = new Thread.UncaughtExceptionHandler() {\\n                               def uncaughtException(t: Thread, e: Throwable) {\\n                                 e.printStackTrace() // is it safe default implementation?\\n                               }\\n                             }) extends AbstractExecutorService {\\n  private val closing = new AtomicInteger(0)\\n  private val taskHead = new AtomicReference[TaskNode](new TaskNode())\\n  private val taskTail = new AtomicReference[TaskNode](taskHead.get)\\n  private val terminations = new CountDownLatch(threadCount)\\n  private val threads = {\\n    val tf = threadFactory // to avoid creating of field for the threadFactory constructor param\\n    val c = closing  // to avoid long field names\\n    val tt = taskTail\\n    val h = handler\\n    val t = terminations\\n    (1 to threadCount).map(_ => tf.newThread(new Worker(c, tt, h, t)))\\n  }\\n  threads.foreach(_.start())\\n\\n  def shutdown() {\\n    shutdownNow()\\n    awaitTermination(0, TimeUnit.MILLISECONDS)\\n  }\\n\\n  def shutdownNow(): java.util.List[Runnable] = {\\n    closing.set(1)\\n    threads.filter(_ ne Thread.currentThread()).foreach(_.interrupt()) // don\\'t interrupt worker thread due call in task\\n    drainRemainingTasks(new java.util.LinkedList[Runnable]())\\n  }\\n\\n  def isShutdown: Boolean = closing.get != 0\\n\\n  def isTerminated: Boolean = terminations.getCount == 0\\n\\n  def awaitTermination(timeout: Long, unit: TimeUnit): Boolean = {\\n    if (threads.exists(_ eq Thread.currentThread())) terminations.countDown() // don\\'t hang up due call in task\\n    terminations.await(timeout, unit)\\n  }\\n\\n  def execute(task: Runnable) {\\n    if (isShutdown) throw new IllegalStateException(\"Cannot execute in terminating/shutdown state\")\\n    if (task eq null) throw new NullPointerException\\n    val n = new TaskNode(task)\\n    taskHead.getAndSet(n).lazySet(n)\\n  }\\n\\n  @tailrec\\n  private def drainRemainingTasks(ts: java.util.List[Runnable]): java.util.List[Runnable] = {\\n    val tn = taskTail.get\\n    val n = tn.get\\n    if ((n ne null) && taskTail.compareAndSet(tn, n)) {\\n      ts.add(n.task)\\n      drainRemainingTasks(ts)\\n    } else ts\\n  }\\n}\\n\\nprivate class Worker(closing: AtomicInteger, taskTail: AtomicReference[TaskNode],\\n                     handler: Thread.UncaughtExceptionHandler, terminations: CountDownLatch) extends Runnable {\\n  def run() {\\n    try {\\n      doWork()\\n    } finally {\\n      terminations.countDown()\\n    }\\n  }\\n\\n  private def doWork() {\\n    while (closing.get == 0) {\\n      try {\\n        val tn = taskTail.get\\n        val n = tn.get\\n        if (n eq null) backOff()\\n        else if (taskTail.compareAndSet(tn, n)) n.run()\\n      } catch {\\n        case ex: InterruptedException => return\\n        case ex: Throwable => onError(ex)\\n      }\\n    }\\n  }\\n\\n  private def backOff() {\\n    LockSupport.parkNanos(100)\\n  }\\n\\n  private def onError(ex: Throwable) {\\n    handler.uncaughtException(Thread.currentThread(), ex)\\n  }\\n}\\n\\nprivate class TaskNode(var task: Runnable = null) extends AtomicReference[TaskNode] {\\n  def run() {\\n    task.run()\\n    task = null // to avoid holding of task reference when queue is empty\\n  }\\n}\\n```\\n\\n### Response:\\n```scala\\n', 'base_prompt': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nRewrite the given scala program to optimize and improve the energy usage. Write the entire code and no other text in the response.\\n```scala\\npackage com.github.plokhotnyuk.actors\\n\\nimport java.util.concurrent._\\nimport java.util.concurrent.atomic.{AtomicReference, AtomicInteger}\\nimport java.lang.InterruptedException\\nimport scala.annotation.tailrec\\nimport java.util.concurrent.locks.LockSupport\\n\\n/**\\n * A high performance implementation of thread pool with fixed number of threads.\\n *\\n * Implementation of task queue based on non-intrusive MPSC node-based queue, described by Dmitriy Vyukov:\\n * http://www.1024cores.net/home/lock-free-algorithms/queues/non-intrusive-mpsc-node-based-queue\\n *\\n * @param threadCount a number of worker threads in pool\\n * @param threadFactory a factory to be used to build worker threads\\n * @param handler the handler for internal worker threads that will be called\\n *                in case of unrecoverable errors encountered while executing tasks.\\n */\\nclass FastThreadPoolExecutor(threadCount: Int = Runtime.getRuntime.availableProcessors(),\\n                             threadFactory: ThreadFactory = new ThreadFactory() {\\n                               def newThread(r: Runnable): Thread = new Thread(r) {\\n                                 setDaemon(true) // is it good reason: \"to avoid stalls on app end in case of missed shutdown call\"?\\n                               }\\n                             },\\n                             handler: Thread.UncaughtExceptionHandler = new Thread.UncaughtExceptionHandler() {\\n                               def uncaughtException(t: Thread, e: Throwable) {\\n                                 e.printStackTrace() // is it safe default implementation?\\n                               }\\n                             }) extends AbstractExecutorService {\\n  private val closing = new AtomicInteger(0)\\n  private val taskHead = new AtomicReference[TaskNode](new TaskNode())\\n  private val taskTail = new AtomicReference[TaskNode](taskHead.get)\\n  private val terminations = new CountDownLatch(threadCount)\\n  private val threads = {\\n    val tf = threadFactory // to avoid creating of field for the threadFactory constructor param\\n    val c = closing  // to avoid long field names\\n    val tt = taskTail\\n    val h = handler\\n    val t = terminations\\n    (1 to threadCount).map(_ => tf.newThread(new Worker(c, tt, h, t)))\\n  }\\n  threads.foreach(_.start())\\n\\n  def shutdown() {\\n    shutdownNow()\\n    awaitTermination(0, TimeUnit.MILLISECONDS)\\n  }\\n\\n  def shutdownNow(): java.util.List[Runnable] = {\\n    closing.set(1)\\n    threads.filter(_ ne Thread.currentThread()).foreach(_.interrupt()) // don\\'t interrupt worker thread due call in task\\n    drainRemainingTasks(new java.util.LinkedList[Runnable]())\\n  }\\n\\n  def isShutdown: Boolean = closing.get != 0\\n\\n  def isTerminated: Boolean = terminations.getCount == 0\\n\\n  def awaitTermination(timeout: Long, unit: TimeUnit): Boolean = {\\n    if (threads.exists(_ eq Thread.currentThread())) terminations.countDown() // don\\'t hang up due call in task\\n    terminations.await(timeout, unit)\\n  }\\n\\n  def execute(task: Runnable) {\\n    if (isShutdown) throw new IllegalStateException(\"Cannot execute in terminating/shutdown state\")\\n    if (task eq null) throw new NullPointerException\\n    val n = new TaskNode(task)\\n    taskHead.getAndSet(n).lazySet(n)\\n  }\\n\\n  @tailrec\\n  private def drainRemainingTasks(ts: java.util.List[Runnable]): java.util.List[Runnable] = {\\n    val tn = taskTail.get\\n    val n = tn.get\\n    if ((n ne null) && taskTail.compareAndSet(tn, n)) {\\n      ts.add(n.task)\\n      drainRemainingTasks(ts)\\n    } else ts\\n  }\\n}\\n\\nprivate class Worker(closing: AtomicInteger, taskTail: AtomicReference[TaskNode],\\n                     handler: Thread.UncaughtExceptionHandler, terminations: CountDownLatch) extends Runnable {\\n  def run() {\\n    try {\\n      doWork()\\n    } finally {\\n      terminations.countDown()\\n    }\\n  }\\n\\n  private def doWork() {\\n    while (closing.get == 0) {\\n      try {\\n        val tn = taskTail.get\\n        val n = tn.get\\n        if (n eq null) backOff()\\n        else if (taskTail.compareAndSet(tn, n)) n.run()\\n      } catch {\\n        case ex: InterruptedException => return\\n        case ex: Throwable => onError(ex)\\n      }\\n    }\\n  }\\n\\n  private def backOff() {\\n    LockSupport.parkNanos(100)\\n  }\\n\\n  private def onError(ex: Throwable) {\\n    handler.uncaughtException(Thread.currentThread(), ex)\\n  }\\n}\\n\\nprivate class TaskNode(var task: Runnable = null) extends AtomicReference[TaskNode] {\\n  def run() {\\n    task.run()\\n    task = null // to avoid holding of task reference when queue is empty\\n  }\\n}\\n```\\n\\n### Response:\\n```scala\\n', 'coding_concepts': 'Below is an instruction that describes a task. The instruction contains concepts formatted as a list of keyword and value pairs separated by newline. The list of concept keywords and their descriptions are:\\n\\n### Keywords:\\n\\n[in] What specific function or class to focus on to implement the required change(s).\\n\\n[+] What specific library, programming or data structure or design concept, or programmer-defined construct in the code to USE or ADD to implement the required change(s)\\n\\n[-] What specific library, programming or data structure or design concept, or programmer-defined construct in the code to NOT USE or REMOVE to implement the required change(s)\\n\\n[implement] What specific function to implement in the class of interest\\n\\n[override] What specific function of the parent class to override and implement in the class of interest\\n\\n[hint] Full or partial textual description of the idea to implement\\n\\nWrite a response that appropriately completes the request.\\n\\n### Instruction:\\n \"Rewrite the code to improve the backoff implementation to be more energy efficient by parking waiting threads until new tasks are submitted.\" Write the entire code and no other text in the response.\\n\\n### Concepts:\\n[-] java.util.concurrent.atomic.{AtomicReference, AtomicInteger}\\n[+] java.util.concurrent.atomic.{AtomicLong, AtomicReference, AtomicInteger}\\n[+] val waitingThreads = new ConcurrentLinkedQueue[Thread]\\n[in] class FastThreadPoolExecutor\\n[in] FastThreadPoolExecutor.execute function\\n[in] Worker class definition\\n[in] Worker.doWork function\\n[in] Worker.execute function\\n[in] Worker.backoff function\\n[-] TaskNode.run function\\n\\n### Given program:\\n```scala\\npackage com.github.plokhotnyuk.actors\\n\\nimport java.util.concurrent._\\nimport java.util.concurrent.atomic.{AtomicReference, AtomicInteger}\\nimport java.lang.InterruptedException\\nimport scala.annotation.tailrec\\nimport java.util.concurrent.locks.LockSupport\\n\\n/**\\n * A high performance implementation of thread pool with fixed number of threads.\\n *\\n * Implementation of task queue based on non-intrusive MPSC node-based queue, described by Dmitriy Vyukov:\\n * http://www.1024cores.net/home/lock-free-algorithms/queues/non-intrusive-mpsc-node-based-queue\\n *\\n * @param threadCount a number of worker threads in pool\\n * @param threadFactory a factory to be used to build worker threads\\n * @param handler the handler for internal worker threads that will be called\\n *                in case of unrecoverable errors encountered while executing tasks.\\n */\\nclass FastThreadPoolExecutor(threadCount: Int = Runtime.getRuntime.availableProcessors(),\\n                             threadFactory: ThreadFactory = new ThreadFactory() {\\n                               def newThread(r: Runnable): Thread = new Thread(r) {\\n                                 setDaemon(true) // is it good reason: \"to avoid stalls on app end in case of missed shutdown call\"?\\n                               }\\n                             },\\n                             handler: Thread.UncaughtExceptionHandler = new Thread.UncaughtExceptionHandler() {\\n                               def uncaughtException(t: Thread, e: Throwable) {\\n                                 e.printStackTrace() // is it safe default implementation?\\n                               }\\n                             }) extends AbstractExecutorService {\\n  private val closing = new AtomicInteger(0)\\n  private val taskHead = new AtomicReference[TaskNode](new TaskNode())\\n  private val taskTail = new AtomicReference[TaskNode](taskHead.get)\\n  private val terminations = new CountDownLatch(threadCount)\\n  private val threads = {\\n    val tf = threadFactory // to avoid creating of field for the threadFactory constructor param\\n    val c = closing  // to avoid long field names\\n    val tt = taskTail\\n    val h = handler\\n    val t = terminations\\n    (1 to threadCount).map(_ => tf.newThread(new Worker(c, tt, h, t)))\\n  }\\n  threads.foreach(_.start())\\n\\n  def shutdown() {\\n    shutdownNow()\\n    awaitTermination(0, TimeUnit.MILLISECONDS)\\n  }\\n\\n  def shutdownNow(): java.util.List[Runnable] = {\\n    closing.set(1)\\n    threads.filter(_ ne Thread.currentThread()).foreach(_.interrupt()) // don\\'t interrupt worker thread due call in task\\n    drainRemainingTasks(new java.util.LinkedList[Runnable]())\\n  }\\n\\n  def isShutdown: Boolean = closing.get != 0\\n\\n  def isTerminated: Boolean = terminations.getCount == 0\\n\\n  def awaitTermination(timeout: Long, unit: TimeUnit): Boolean = {\\n    if (threads.exists(_ eq Thread.currentThread())) terminations.countDown() // don\\'t hang up due call in task\\n    terminations.await(timeout, unit)\\n  }\\n\\n  def execute(task: Runnable) {\\n    if (isShutdown) throw new IllegalStateException(\"Cannot execute in terminating/shutdown state\")\\n    if (task eq null) throw new NullPointerException\\n    val n = new TaskNode(task)\\n    taskHead.getAndSet(n).lazySet(n)\\n  }\\n\\n  @tailrec\\n  private def drainRemainingTasks(ts: java.util.List[Runnable]): java.util.List[Runnable] = {\\n    val tn = taskTail.get\\n    val n = tn.get\\n    if ((n ne null) && taskTail.compareAndSet(tn, n)) {\\n      ts.add(n.task)\\n      drainRemainingTasks(ts)\\n    } else ts\\n  }\\n}\\n\\nprivate class Worker(closing: AtomicInteger, taskTail: AtomicReference[TaskNode],\\n                     handler: Thread.UncaughtExceptionHandler, terminations: CountDownLatch) extends Runnable {\\n  def run() {\\n    try {\\n      doWork()\\n    } finally {\\n      terminations.countDown()\\n    }\\n  }\\n\\n  private def doWork() {\\n    while (closing.get == 0) {\\n      try {\\n        val tn = taskTail.get\\n        val n = tn.get\\n        if (n eq null) backOff()\\n        else if (taskTail.compareAndSet(tn, n)) n.run()\\n      } catch {\\n        case ex: InterruptedException => return\\n        case ex: Throwable => onError(ex)\\n      }\\n    }\\n  }\\n\\n  private def backOff() {\\n    LockSupport.parkNanos(100)\\n  }\\n\\n  private def onError(ex: Throwable) {\\n    handler.uncaughtException(Thread.currentThread(), ex)\\n  }\\n}\\n\\nprivate class TaskNode(var task: Runnable = null) extends AtomicReference[TaskNode] {\\n  def run() {\\n    task.run()\\n    task = null // to avoid holding of task reference when queue is empty\\n  }\\n}\\n```\\n\\n### Response:\\n```scala\\n', 'classification_left_prompt': \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n### Instruction:\\n\\nOnly one of the two code snippets has a lower energy usage.\\n\\nCode-A:\\n/* -*- Mode: Java; tab-width: 2; indent-tabs-mode: nil; c-basic-offset: 2 -*- /\\n/* vim: set shiftwidth=2 tabstop=2 autoindent cindent expandtab: */\\n\\n'use strict';\\n\\nvar BatteryManager = {\\n  TOASTER_TIMEOUT: 5000,\\n  TRANSITION_SPEED: 1.8,\\n  TRANSITION_FRACTION: 0.30,\\n\\n  AUTO_SHUTDOWN_LEVEL: 0.02,\\n\\n  _notification: null,\\n  _screenOn: true,\\n  _previousLevel: 0,\\n\\n  getAllElements: function bm_getAllElements() {\\n    this.screen = document.getElementById('screen');\\n    this.overlay = document.getElementById('system-overlay');\\n    this.notification = document.getElementById('battery');\\n  },\\n\\n  checkBatteryDrainage: function bm_checkBatteryDrainage() {\\n    var battery = window.navigator.battery;\\n    if (!battery)\\n      return;\\n\\n    if (battery.level <= this.AUTO_SHUTDOWN_LEVEL)\\n      SleepMenu.startPowerOff(false);\\n  },\\n\\n  init: function bm_init() {\\n    this.getAllElements();\\n    var battery = window.navigator.battery;\\n    if (battery) {\\n      // When the device is booted, check if the battery is drained.\\n      // If so, SleepMenu.startPowerOff() would be called.\\n      this.checkBatteryDrainage();\\n\\n      battery.addEventListener('levelchange', this);\\n      battery.addEventListener('chargingchange', this);\\n    }\\n    window.addEventListener('screenchange', this);\\n    this._toasterGD = new GestureDetector(this.notification);\\n    ['mousedown', 'swipe'].forEach(function(evt) {\\n      this.notification.addEventListener(evt, this);\\n    }, this);\\n  },\\n\\n  handleEvent: function bm_handleEvent(evt) {\\n    switch (evt.type) {\\n      case 'screenchange':\\n        this._screenOn = evt.detail.screenEnabled;\\n        break;\\n\\n      case 'levelchange':\\n        var battery = window.navigator.battery;\\n        if (!battery)\\n          return;\\n\\n        this.checkBatteryDrainage();\\n\\n        var level = Math.min(100, Math.round(battery.level * 100));\\n\\n        if (this._screenOn) {\\n          this.notification.dataset.level = level;\\n\\n          if (!battery.charging && this._previousLevel != level && level == 10)\\n            this.display();\\n        }\\n\\n        this._previousLevel = level;\\n\\n        PowerSaveHandler.onBatteryChange();\\n        break;\\n      case 'chargingchange':\\n        PowerSaveHandler.onBatteryChange();\\n\\n        var battery = window.navigator.battery;\\n        // We turn the screen on if needed in order to let\\n        // the user knows the device is charging\\n        if (battery && battery.charging && !this._screenOn)\\n          ScreenManager.turnScreenOn();\\n        break;\\n\\n      case 'mousedown':\\n        this.mousedown(evt);\\n        break;\\n      case 'swipe':\\n        this.swipe(evt);\\n        break;\\n    }\\n  },\\n\\n  display: function bm_display() {\\n    var overlayClass = this.overlay.classList;\\n    var notificationClass = this.notification.classList;\\n\\n    overlayClass.add('battery');\\n    notificationClass.add('visible');\\n    this._toasterGD.startDetecting();\\n\\n    if (this._toasterTimeout)\\n      clearTimeout(this._toasterTimeout);\\n\\n    this._toasterTimeout = setTimeout((function() {\\n      overlayClass.remove('battery');\\n      notificationClass.remove('visible');\\n      this._toasterTimeout = null;\\n      this._toasterGD.stopDetecting();\\n    }).bind(this), this.TOASTER_TIMEOUT);\\n  },\\n\\n  // Swipe handling\\n  mousedown: function bm_mousedown(evt) {\\n    evt.preventDefault();\\n    this._containerWidth = this.overlay.clientWidth;\\n  },\\n\\n  swipe: function bm_swipe(evt) {\\n    var detail = evt.detail;\\n    var distance = detail.start.screenX - detail.end.screenX;\\n    var fastEnough = Math.abs(detail.vx) > this.TRANSITION_SPEED;\\n    var farEnough = Math.abs(distance) >\\n      this._containerWidth * this.TRANSITION_FRACTION;\\n\\n    // If the swipe distance is too short or swipe speed is too slow,\\n    // do nothing.\\n    if (!(farEnough || fastEnough))\\n      return;\\n\\n    var self = this;\\n    this.notification.addEventListener('animationend', function animationend() {\\n      self.notification.removeEventListener('animationend', animationend);\\n      self.notification.classList.remove('visible');\\n      self.notification.classList.remove('disappearing');\\n      self.overlay.classList.remove('battery');\\n    });\\n    this.notification.classList.add('disappearing');\\n  }\\n};\\n\\nvar PowerSaveHandler = (function PowerSaveHandler() {\\n\\n  var _powerSaveResume = {};\\n  var _powerSaveEnabled = false;\\n  var _states = {\\n    'wifi.enabled' : false,\\n    'ril.data.enabled' : false,\\n    'bluetooth.enabled' : false,\\n    'geolocation.enabled' : false\\n  };\\n\\n  function init() {\\n    SettingsListener.observe('powersave.enabled', false,\\n      function sl_getPowerSave(value) {\\n        var enabled = value;\\n        if (enabled) {\\n          enablePowerSave();\\n        } else {\\n          disablePowerSave();\\n        }\\n        _powerSaveEnabled = enabled;\\n      });\\n\\n    // Monitor the states of various modules\\n    for (var j in _states) {\\n      SettingsListener.observe(j, true, function getState(state, value) {\\n        _states[state] = value;\\n      }.bind(null, j));\\n    }\\n  }\\n\\n  // XXX Break down obj keys in a for each loop because mozSettings\\n  // does not currently supports multiple keys in one set()\\n  // https://bugzilla.mozilla.org/show_bug.cgi?id=779381\\n  function setMozSettings(keypairs) {\\n    var setlock = SettingsListener.getSettingsLock();\\n    for (var key in keypairs) {\\n      var obj = {};\\n      obj[key] = keypairs[key];\\n      setlock.set(obj);\\n    }\\n  }\\n\\n  function enablePowerSave() {\\n    // Keep the original states of various modules\\n    for (var j in _states) {\\n      _powerSaveResume[j] = _states[j];\\n    }\\n\\n    var settingsToSet = {\\n      // Turn off Wifi\\n      'wifi.enabled' : false,\\n      // Turn off Data\\n      'ril.data.enabled' : false,\\n      // Turn off Bluetooth\\n      'bluetooth.enabled' : false,\\n      // Turn off Geolocation\\n      'geolocation.enabled' : false\\n    };\\n\\n    setMozSettings(settingsToSet);\\n  }\\n\\n  function disablePowerSave() {\\n\\n    var settingsToSet = {};\\n\\n    for (var state in _powerSaveResume) {\\n      if (_powerSaveResume[state] == true)\\n        settingsToSet[state] = true;\\n    }\\n\\n    setMozSettings(settingsToSet);\\n  }\\n\\n  function onBatteryChange() {\\n    var battery = window.navigator.battery;\\n\\n    if (battery.charging) {\\n      if (_powerSaveEnabled)\\n        setMozSettings({'powersave.enabled' : false});\\n\\n      return;\\n    }\\n\\n    SettingsListener.observe('powersave.threshold', 0,\\n      function getThreshold(value) {\\n        if (battery.level <= value && !_powerSaveEnabled) {\\n          setMozSettings({'powersave.enabled' : true});\\n          return;\\n        }\\n\\n        if (value != 0 && battery.level > value && _powerSaveEnabled) {\\n          setMozSettings({'powersave.enabled' : false});\\n          return;\\n        }\\n    });\\n  }\\n\\n  return {\\n    init: init,\\n    onBatteryChange: onBatteryChange\\n  };\\n})();\\n\\n// init PowerSaveHandler first, since it will be used by BatteryManager\\nPowerSaveHandler.init();\\nBatteryManager.init();\\n\\n\\nCode-B:\\n/* -*- Mode: Java; tab-width: 2; indent-tabs-mode: nil; c-basic-offset: 2 -*- /\\n/* vim: set shiftwidth=2 tabstop=2 autoindent cindent expandtab: */\\n\\n'use strict';\\n\\nvar BatteryManager = {\\n  TOASTER_TIMEOUT: 5000,\\n  TRANSITION_SPEED: 1.8,\\n  TRANSITION_FRACTION: 0.30,\\n\\n  AUTO_SHUTDOWN_LEVEL: 0.02,\\n\\n  _notification: null,\\n  _screenOn: true,\\n  _previousLevel: 0,\\n\\n  getAllElements: function bm_getAllElements() {\\n    this.screen = document.getElementById('screen');\\n    this.overlay = document.getElementById('system-overlay');\\n    this.notification = document.getElementById('battery');\\n  },\\n\\n  checkBatteryDrainage: function bm_checkBatteryDrainage() {\\n    var battery = window.navigator.battery;\\n    if (!battery)\\n      return;\\n\\n    if (battery.level <= this.AUTO_SHUTDOWN_LEVEL)\\n      SleepMenu.startPowerOff(false);\\n  },\\n\\n  init: function bm_init() {\\n    this.getAllElements();\\n    var battery = window.navigator.battery;\\n    if (battery) {\\n      // When the device is booted, check if the battery is drained.\\n      // If so, SleepMenu.startPowerOff() would be called.\\n      this.checkBatteryDrainage();\\n\\n      battery.addEventListener('levelchange', this);\\n      battery.addEventListener('chargingchange', this);\\n    }\\n    window.addEventListener('screenchange', this);\\n    this._toasterGD = new GestureDetector(this.notification);\\n    ['mousedown', 'swipe'].forEach(function(evt) {\\n      this.notification.addEventListener(evt, this);\\n    }, this);\\n  },\\n\\n  handleEvent: function bm_handleEvent(evt) {\\n    switch (evt.type) {\\n      case 'screenchange':\\n        this._screenOn = evt.detail.screenEnabled;\\n        break;\\n\\n      case 'levelchange':\\n        var battery = window.navigator.battery;\\n        if (!battery)\\n          return;\\n\\n        this.checkBatteryDrainage();\\n\\n        var level = Math.min(100, Math.round(battery.level * 100));\\n\\n        if (this._screenOn) {\\n          this.notification.dataset.level = level;\\n\\n          if (!battery.charging && this._previousLevel != level && level == 10)\\n            this.display();\\n        }\\n\\n        this._previousLevel = level;\\n\\n        PowerSaveHandler.onBatteryChange();\\n        break;\\n      case 'chargingchange':\\n        PowerSaveHandler.onBatteryChange();\\n\\n        var battery = window.navigator.battery;\\n        // We turn the screen on if needed in order to let\\n        // the user knows the device is charging\\n        if (battery && battery.charging && !this._screenOn)\\n          ScreenManager.turnScreenOn();\\n        break;\\n\\n      case 'mousedown':\\n        this.mousedown(evt);\\n        break;\\n      case 'swipe':\\n        this.swipe(evt);\\n        break;\\n    }\\n  },\\n\\n  display: function bm_display() {\\n    var overlayClass = this.overlay.classList;\\n    var notificationClass = this.notification.classList;\\n\\n    overlayClass.add('battery');\\n    notificationClass.add('visible');\\n    this._toasterGD.startDetecting();\\n\\n    if (this._toasterTimeout)\\n      clearTimeout(this._toasterTimeout);\\n\\n    this._toasterTimeout = setTimeout((function() {\\n      overlayClass.remove('battery');\\n      notificationClass.remove('visible');\\n      this._toasterTimeout = null;\\n      this._toasterGD.stopDetecting();\\n    }).bind(this), this.TOASTER_TIMEOUT);\\n  },\\n\\n  // Swipe handling\\n  mousedown: function bm_mousedown(evt) {\\n    evt.preventDefault();\\n    this._containerWidth = this.overlay.clientWidth;\\n  },\\n\\n  swipe: function bm_swipe(evt) {\\n    var detail = evt.detail;\\n    var distance = detail.start.screenX - detail.end.screenX;\\n    var fastEnough = Math.abs(detail.vx) > this.TRANSITION_SPEED;\\n    var farEnough = Math.abs(distance) >\\n      this._containerWidth * this.TRANSITION_FRACTION;\\n\\n    // If the swipe distance is too short or swipe speed is too slow,\\n    // do nothing.\\n    if (!(farEnough || fastEnough))\\n      return;\\n\\n    var self = this;\\n    this.notification.addEventListener('animationend', function animationend() {\\n      self.notification.removeEventListener('animationend', animationend);\\n      self.notification.classList.remove('visible');\\n      self.notification.classList.remove('disappearing');\\n      self.overlay.classList.remove('battery');\\n    });\\n    this.notification.classList.add('disappearing');\\n  }\\n};\\n\\nvar PowerSaveHandler = (function PowerSaveHandler() {\\n\\n  var _powerSaveResume = {};\\n  var _powerSaveEnabled = false;\\n  var _states = {\\n    'wifi.enabled' : false,\\n    'ril.data.enabled' : false,\\n    'bluetooth.enabled' : false,\\n    'geolocation.enabled' : false\\n  };\\n\\n  function init() {\\n    SettingsListener.observe('powersave.enabled', false,\\n      function sl_getPowerSave(value) {\\n        var enabled = value;\\n        if (enabled) {\\n          enablePowerSave();\\n        } else {\\n          disablePowerSave();\\n        }\\n        _powerSaveEnabled = enabled;\\n      });\\n\\n    // Monitor the states of various modules\\n    for (var j in _states) {\\n      SettingsListener.observe(j, true, function getState(state, value) {\\n        _states[state] = value;\\n      }.bind(null, j));\\n    }\\n  }\\n\\n  // XXX Break down obj keys in a for each loop because mozSettings\\n  // does not currently supports multiple keys in one set()\\n  // https://bugzilla.mozilla.org/show_bug.cgi?id=779381\\n  function setMozSettings(keypairs) {\\n    var setlock = SettingsListener.getSettingsLock();\\n    for (var key in keypairs) {\\n      var obj = {};\\n      obj[key] = keypairs[key];\\n      setlock.set(obj);\\n    }\\n  }\\n\\n  function enablePowerSave() {\\n    // Keep the original states of various modules\\n    for (var j in _states) {\\n      _powerSaveResume[j] = _states[j];\\n    }\\n\\n    var settingsToSet = {\\n      // Turn off Wifi\\n      'wifi.enabled' : false,\\n      // Turn off Data\\n      'ril.data.enabled' : false,\\n      // Turn off Bluetooth\\n      'bluetooth.enabled' : false,\\n      // Turn off Geolocation\\n      'geolocation.enabled' : false\\n    };\\n\\n    setMozSettings(settingsToSet);\\n  }\\n\\n  function disablePowerSave() {\\n\\n    var settingsToSet = {};\\n\\n    for (var state in _powerSaveResume) {\\n      if (_powerSaveResume[state] == true)\\n        settingsToSet[state] = true;\\n    }\\n\\n    setMozSettings(settingsToSet);\\n  }\\n\\n  function onBatteryChange() {\\n    var battery = window.navigator.battery;\\n\\n    if (battery.charging) {\\n      if (_powerSaveEnabled)\\n        setMozSettings({'powersave.enabled' : false});\\n\\n      return;\\n    }\\n\\n    SettingsListener.observe('powersave.threshold', 0,\\n      function getThreshold(value) {\\n        if (battery.level <= value && !_powerSaveEnabled) {\\n          setMozSettings({'powersave.enabled' : true});\\n          return;\\n        }\\n\\n        if (battery.level > value && _powerSaveEnabled) {\\n          setMozSettings({'powersave.enabled' : false});\\n          return;\\n        }\\n    });\\n  }\\n\\n  return {\\n    init: init,\\n    onBatteryChange: onBatteryChange\\n  };\\n})();\\n\\n// init PowerSaveHandler first, since it will be used by BatteryManager\\nPowerSaveHandler.init();\\nBatteryManager.init();\\n\\n\\nPlease select the code snippet from Code-A or Code-B with a lower energy usage utilization.\\n\\n### Response: Code-\", 'classification_left_label': 'A', 'classification_right_prompt': \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n### Instruction:\\n\\nOnly one of the two code snippets has a lower energy usage.\\n\\nCode-A:\\n/* -*- Mode: Java; tab-width: 2; indent-tabs-mode: nil; c-basic-offset: 2 -*- /\\n/* vim: set shiftwidth=2 tabstop=2 autoindent cindent expandtab: */\\n\\n'use strict';\\n\\nvar BatteryManager = {\\n  TOASTER_TIMEOUT: 5000,\\n  TRANSITION_SPEED: 1.8,\\n  TRANSITION_FRACTION: 0.30,\\n\\n  AUTO_SHUTDOWN_LEVEL: 0.02,\\n\\n  _notification: null,\\n  _screenOn: true,\\n  _previousLevel: 0,\\n\\n  getAllElements: function bm_getAllElements() {\\n    this.screen = document.getElementById('screen');\\n    this.overlay = document.getElementById('system-overlay');\\n    this.notification = document.getElementById('battery');\\n  },\\n\\n  checkBatteryDrainage: function bm_checkBatteryDrainage() {\\n    var battery = window.navigator.battery;\\n    if (!battery)\\n      return;\\n\\n    if (battery.level <= this.AUTO_SHUTDOWN_LEVEL)\\n      SleepMenu.startPowerOff(false);\\n  },\\n\\n  init: function bm_init() {\\n    this.getAllElements();\\n    var battery = window.navigator.battery;\\n    if (battery) {\\n      // When the device is booted, check if the battery is drained.\\n      // If so, SleepMenu.startPowerOff() would be called.\\n      this.checkBatteryDrainage();\\n\\n      battery.addEventListener('levelchange', this);\\n      battery.addEventListener('chargingchange', this);\\n    }\\n    window.addEventListener('screenchange', this);\\n    this._toasterGD = new GestureDetector(this.notification);\\n    ['mousedown', 'swipe'].forEach(function(evt) {\\n      this.notification.addEventListener(evt, this);\\n    }, this);\\n  },\\n\\n  handleEvent: function bm_handleEvent(evt) {\\n    switch (evt.type) {\\n      case 'screenchange':\\n        this._screenOn = evt.detail.screenEnabled;\\n        break;\\n\\n      case 'levelchange':\\n        var battery = window.navigator.battery;\\n        if (!battery)\\n          return;\\n\\n        this.checkBatteryDrainage();\\n\\n        var level = Math.min(100, Math.round(battery.level * 100));\\n\\n        if (this._screenOn) {\\n          this.notification.dataset.level = level;\\n\\n          if (!battery.charging && this._previousLevel != level && level == 10)\\n            this.display();\\n        }\\n\\n        this._previousLevel = level;\\n\\n        PowerSaveHandler.onBatteryChange();\\n        break;\\n      case 'chargingchange':\\n        PowerSaveHandler.onBatteryChange();\\n\\n        var battery = window.navigator.battery;\\n        // We turn the screen on if needed in order to let\\n        // the user knows the device is charging\\n        if (battery && battery.charging && !this._screenOn)\\n          ScreenManager.turnScreenOn();\\n        break;\\n\\n      case 'mousedown':\\n        this.mousedown(evt);\\n        break;\\n      case 'swipe':\\n        this.swipe(evt);\\n        break;\\n    }\\n  },\\n\\n  display: function bm_display() {\\n    var overlayClass = this.overlay.classList;\\n    var notificationClass = this.notification.classList;\\n\\n    overlayClass.add('battery');\\n    notificationClass.add('visible');\\n    this._toasterGD.startDetecting();\\n\\n    if (this._toasterTimeout)\\n      clearTimeout(this._toasterTimeout);\\n\\n    this._toasterTimeout = setTimeout((function() {\\n      overlayClass.remove('battery');\\n      notificationClass.remove('visible');\\n      this._toasterTimeout = null;\\n      this._toasterGD.stopDetecting();\\n    }).bind(this), this.TOASTER_TIMEOUT);\\n  },\\n\\n  // Swipe handling\\n  mousedown: function bm_mousedown(evt) {\\n    evt.preventDefault();\\n    this._containerWidth = this.overlay.clientWidth;\\n  },\\n\\n  swipe: function bm_swipe(evt) {\\n    var detail = evt.detail;\\n    var distance = detail.start.screenX - detail.end.screenX;\\n    var fastEnough = Math.abs(detail.vx) > this.TRANSITION_SPEED;\\n    var farEnough = Math.abs(distance) >\\n      this._containerWidth * this.TRANSITION_FRACTION;\\n\\n    // If the swipe distance is too short or swipe speed is too slow,\\n    // do nothing.\\n    if (!(farEnough || fastEnough))\\n      return;\\n\\n    var self = this;\\n    this.notification.addEventListener('animationend', function animationend() {\\n      self.notification.removeEventListener('animationend', animationend);\\n      self.notification.classList.remove('visible');\\n      self.notification.classList.remove('disappearing');\\n      self.overlay.classList.remove('battery');\\n    });\\n    this.notification.classList.add('disappearing');\\n  }\\n};\\n\\nvar PowerSaveHandler = (function PowerSaveHandler() {\\n\\n  var _powerSaveResume = {};\\n  var _powerSaveEnabled = false;\\n  var _states = {\\n    'wifi.enabled' : false,\\n    'ril.data.enabled' : false,\\n    'bluetooth.enabled' : false,\\n    'geolocation.enabled' : false\\n  };\\n\\n  function init() {\\n    SettingsListener.observe('powersave.enabled', false,\\n      function sl_getPowerSave(value) {\\n        var enabled = value;\\n        if (enabled) {\\n          enablePowerSave();\\n        } else {\\n          disablePowerSave();\\n        }\\n        _powerSaveEnabled = enabled;\\n      });\\n\\n    // Monitor the states of various modules\\n    for (var j in _states) {\\n      SettingsListener.observe(j, true, function getState(state, value) {\\n        _states[state] = value;\\n      }.bind(null, j));\\n    }\\n  }\\n\\n  // XXX Break down obj keys in a for each loop because mozSettings\\n  // does not currently supports multiple keys in one set()\\n  // https://bugzilla.mozilla.org/show_bug.cgi?id=779381\\n  function setMozSettings(keypairs) {\\n    var setlock = SettingsListener.getSettingsLock();\\n    for (var key in keypairs) {\\n      var obj = {};\\n      obj[key] = keypairs[key];\\n      setlock.set(obj);\\n    }\\n  }\\n\\n  function enablePowerSave() {\\n    // Keep the original states of various modules\\n    for (var j in _states) {\\n      _powerSaveResume[j] = _states[j];\\n    }\\n\\n    var settingsToSet = {\\n      // Turn off Wifi\\n      'wifi.enabled' : false,\\n      // Turn off Data\\n      'ril.data.enabled' : false,\\n      // Turn off Bluetooth\\n      'bluetooth.enabled' : false,\\n      // Turn off Geolocation\\n      'geolocation.enabled' : false\\n    };\\n\\n    setMozSettings(settingsToSet);\\n  }\\n\\n  function disablePowerSave() {\\n\\n    var settingsToSet = {};\\n\\n    for (var state in _powerSaveResume) {\\n      if (_powerSaveResume[state] == true)\\n        settingsToSet[state] = true;\\n    }\\n\\n    setMozSettings(settingsToSet);\\n  }\\n\\n  function onBatteryChange() {\\n    var battery = window.navigator.battery;\\n\\n    if (battery.charging) {\\n      if (_powerSaveEnabled)\\n        setMozSettings({'powersave.enabled' : false});\\n\\n      return;\\n    }\\n\\n    SettingsListener.observe('powersave.threshold', 0,\\n      function getThreshold(value) {\\n        if (battery.level <= value && !_powerSaveEnabled) {\\n          setMozSettings({'powersave.enabled' : true});\\n          return;\\n        }\\n\\n        if (battery.level > value && _powerSaveEnabled) {\\n          setMozSettings({'powersave.enabled' : false});\\n          return;\\n        }\\n    });\\n  }\\n\\n  return {\\n    init: init,\\n    onBatteryChange: onBatteryChange\\n  };\\n})();\\n\\n// init PowerSaveHandler first, since it will be used by BatteryManager\\nPowerSaveHandler.init();\\nBatteryManager.init();\\n\\n\\nCode-B:\\n/* -*- Mode: Java; tab-width: 2; indent-tabs-mode: nil; c-basic-offset: 2 -*- /\\n/* vim: set shiftwidth=2 tabstop=2 autoindent cindent expandtab: */\\n\\n'use strict';\\n\\nvar BatteryManager = {\\n  TOASTER_TIMEOUT: 5000,\\n  TRANSITION_SPEED: 1.8,\\n  TRANSITION_FRACTION: 0.30,\\n\\n  AUTO_SHUTDOWN_LEVEL: 0.02,\\n\\n  _notification: null,\\n  _screenOn: true,\\n  _previousLevel: 0,\\n\\n  getAllElements: function bm_getAllElements() {\\n    this.screen = document.getElementById('screen');\\n    this.overlay = document.getElementById('system-overlay');\\n    this.notification = document.getElementById('battery');\\n  },\\n\\n  checkBatteryDrainage: function bm_checkBatteryDrainage() {\\n    var battery = window.navigator.battery;\\n    if (!battery)\\n      return;\\n\\n    if (battery.level <= this.AUTO_SHUTDOWN_LEVEL)\\n      SleepMenu.startPowerOff(false);\\n  },\\n\\n  init: function bm_init() {\\n    this.getAllElements();\\n    var battery = window.navigator.battery;\\n    if (battery) {\\n      // When the device is booted, check if the battery is drained.\\n      // If so, SleepMenu.startPowerOff() would be called.\\n      this.checkBatteryDrainage();\\n\\n      battery.addEventListener('levelchange', this);\\n      battery.addEventListener('chargingchange', this);\\n    }\\n    window.addEventListener('screenchange', this);\\n    this._toasterGD = new GestureDetector(this.notification);\\n    ['mousedown', 'swipe'].forEach(function(evt) {\\n      this.notification.addEventListener(evt, this);\\n    }, this);\\n  },\\n\\n  handleEvent: function bm_handleEvent(evt) {\\n    switch (evt.type) {\\n      case 'screenchange':\\n        this._screenOn = evt.detail.screenEnabled;\\n        break;\\n\\n      case 'levelchange':\\n        var battery = window.navigator.battery;\\n        if (!battery)\\n          return;\\n\\n        this.checkBatteryDrainage();\\n\\n        var level = Math.min(100, Math.round(battery.level * 100));\\n\\n        if (this._screenOn) {\\n          this.notification.dataset.level = level;\\n\\n          if (!battery.charging && this._previousLevel != level && level == 10)\\n            this.display();\\n        }\\n\\n        this._previousLevel = level;\\n\\n        PowerSaveHandler.onBatteryChange();\\n        break;\\n      case 'chargingchange':\\n        PowerSaveHandler.onBatteryChange();\\n\\n        var battery = window.navigator.battery;\\n        // We turn the screen on if needed in order to let\\n        // the user knows the device is charging\\n        if (battery && battery.charging && !this._screenOn)\\n          ScreenManager.turnScreenOn();\\n        break;\\n\\n      case 'mousedown':\\n        this.mousedown(evt);\\n        break;\\n      case 'swipe':\\n        this.swipe(evt);\\n        break;\\n    }\\n  },\\n\\n  display: function bm_display() {\\n    var overlayClass = this.overlay.classList;\\n    var notificationClass = this.notification.classList;\\n\\n    overlayClass.add('battery');\\n    notificationClass.add('visible');\\n    this._toasterGD.startDetecting();\\n\\n    if (this._toasterTimeout)\\n      clearTimeout(this._toasterTimeout);\\n\\n    this._toasterTimeout = setTimeout((function() {\\n      overlayClass.remove('battery');\\n      notificationClass.remove('visible');\\n      this._toasterTimeout = null;\\n      this._toasterGD.stopDetecting();\\n    }).bind(this), this.TOASTER_TIMEOUT);\\n  },\\n\\n  // Swipe handling\\n  mousedown: function bm_mousedown(evt) {\\n    evt.preventDefault();\\n    this._containerWidth = this.overlay.clientWidth;\\n  },\\n\\n  swipe: function bm_swipe(evt) {\\n    var detail = evt.detail;\\n    var distance = detail.start.screenX - detail.end.screenX;\\n    var fastEnough = Math.abs(detail.vx) > this.TRANSITION_SPEED;\\n    var farEnough = Math.abs(distance) >\\n      this._containerWidth * this.TRANSITION_FRACTION;\\n\\n    // If the swipe distance is too short or swipe speed is too slow,\\n    // do nothing.\\n    if (!(farEnough || fastEnough))\\n      return;\\n\\n    var self = this;\\n    this.notification.addEventListener('animationend', function animationend() {\\n      self.notification.removeEventListener('animationend', animationend);\\n      self.notification.classList.remove('visible');\\n      self.notification.classList.remove('disappearing');\\n      self.overlay.classList.remove('battery');\\n    });\\n    this.notification.classList.add('disappearing');\\n  }\\n};\\n\\nvar PowerSaveHandler = (function PowerSaveHandler() {\\n\\n  var _powerSaveResume = {};\\n  var _powerSaveEnabled = false;\\n  var _states = {\\n    'wifi.enabled' : false,\\n    'ril.data.enabled' : false,\\n    'bluetooth.enabled' : false,\\n    'geolocation.enabled' : false\\n  };\\n\\n  function init() {\\n    SettingsListener.observe('powersave.enabled', false,\\n      function sl_getPowerSave(value) {\\n        var enabled = value;\\n        if (enabled) {\\n          enablePowerSave();\\n        } else {\\n          disablePowerSave();\\n        }\\n        _powerSaveEnabled = enabled;\\n      });\\n\\n    // Monitor the states of various modules\\n    for (var j in _states) {\\n      SettingsListener.observe(j, true, function getState(state, value) {\\n        _states[state] = value;\\n      }.bind(null, j));\\n    }\\n  }\\n\\n  // XXX Break down obj keys in a for each loop because mozSettings\\n  // does not currently supports multiple keys in one set()\\n  // https://bugzilla.mozilla.org/show_bug.cgi?id=779381\\n  function setMozSettings(keypairs) {\\n    var setlock = SettingsListener.getSettingsLock();\\n    for (var key in keypairs) {\\n      var obj = {};\\n      obj[key] = keypairs[key];\\n      setlock.set(obj);\\n    }\\n  }\\n\\n  function enablePowerSave() {\\n    // Keep the original states of various modules\\n    for (var j in _states) {\\n      _powerSaveResume[j] = _states[j];\\n    }\\n\\n    var settingsToSet = {\\n      // Turn off Wifi\\n      'wifi.enabled' : false,\\n      // Turn off Data\\n      'ril.data.enabled' : false,\\n      // Turn off Bluetooth\\n      'bluetooth.enabled' : false,\\n      // Turn off Geolocation\\n      'geolocation.enabled' : false\\n    };\\n\\n    setMozSettings(settingsToSet);\\n  }\\n\\n  function disablePowerSave() {\\n\\n    var settingsToSet = {};\\n\\n    for (var state in _powerSaveResume) {\\n      if (_powerSaveResume[state] == true)\\n        settingsToSet[state] = true;\\n    }\\n\\n    setMozSettings(settingsToSet);\\n  }\\n\\n  function onBatteryChange() {\\n    var battery = window.navigator.battery;\\n\\n    if (battery.charging) {\\n      if (_powerSaveEnabled)\\n        setMozSettings({'powersave.enabled' : false});\\n\\n      return;\\n    }\\n\\n    SettingsListener.observe('powersave.threshold', 0,\\n      function getThreshold(value) {\\n        if (battery.level <= value && !_powerSaveEnabled) {\\n          setMozSettings({'powersave.enabled' : true});\\n          return;\\n        }\\n\\n        if (value != 0 && battery.level > value && _powerSaveEnabled) {\\n          setMozSettings({'powersave.enabled' : false});\\n          return;\\n        }\\n    });\\n  }\\n\\n  return {\\n    init: init,\\n    onBatteryChange: onBatteryChange\\n  };\\n})();\\n\\n// init PowerSaveHandler first, since it will be used by BatteryManager\\nPowerSaveHandler.init();\\nBatteryManager.init();\\n\\n\\nPlease select the code snippet from Code-A or Code-B with a lower energy usage utilization.\\n\\n### Response: Code-\", 'classification_right_label': 'B', 'input_text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nRewrite the given scala program to optimize and improve the energy usage. Write the entire code and no other text in the response.\\n```scala\\npackage com.github.plokhotnyuk.actors\\n\\nimport java.util.concurrent._\\nimport java.util.concurrent.atomic.{AtomicReference, AtomicInteger}\\nimport java.lang.InterruptedException\\nimport scala.annotation.tailrec\\nimport java.util.concurrent.locks.LockSupport\\n\\n/**\\n * A high performance implementation of thread pool with fixed number of threads.\\n *\\n * Implementation of task queue based on non-intrusive MPSC node-based queue, described by Dmitriy Vyukov:\\n * http://www.1024cores.net/home/lock-free-algorithms/queues/non-intrusive-mpsc-node-based-queue\\n *\\n * @param threadCount a number of worker threads in pool\\n * @param threadFactory a factory to be used to build worker threads\\n * @param handler the handler for internal worker threads that will be called\\n *                in case of unrecoverable errors encountered while executing tasks.\\n */\\nclass FastThreadPoolExecutor(threadCount: Int = Runtime.getRuntime.availableProcessors(),\\n                             threadFactory: ThreadFactory = new ThreadFactory() {\\n                               def newThread(r: Runnable): Thread = new Thread(r) {\\n                                 setDaemon(true) // is it good reason: \"to avoid stalls on app end in case of missed shutdown call\"?\\n                               }\\n                             },\\n                             handler: Thread.UncaughtExceptionHandler = new Thread.UncaughtExceptionHandler() {\\n                               def uncaughtException(t: Thread, e: Throwable) {\\n                                 e.printStackTrace() // is it safe default implementation?\\n                               }\\n                             }) extends AbstractExecutorService {\\n  private val closing = new AtomicInteger(0)\\n  private val taskHead = new AtomicReference[TaskNode](new TaskNode())\\n  private val taskTail = new AtomicReference[TaskNode](taskHead.get)\\n  private val terminations = new CountDownLatch(threadCount)\\n  private val threads = {\\n    val tf = threadFactory // to avoid creating of field for the threadFactory constructor param\\n    val c = closing  // to avoid long field names\\n    val tt = taskTail\\n    val h = handler\\n    val t = terminations\\n    (1 to threadCount).map(_ => tf.newThread(new Worker(c, tt, h, t)))\\n  }\\n  threads.foreach(_.start())\\n\\n  def shutdown() {\\n    shutdownNow()\\n    awaitTermination(0, TimeUnit.MILLISECONDS)\\n  }\\n\\n  def shutdownNow(): java.util.List[Runnable] = {\\n    closing.set(1)\\n    threads.filter(_ ne Thread.currentThread()).foreach(_.interrupt()) // don\\'t interrupt worker thread due call in task\\n    drainRemainingTasks(new java.util.LinkedList[Runnable]())\\n  }\\n\\n  def isShutdown: Boolean = closing.get != 0\\n\\n  def isTerminated: Boolean = terminations.getCount == 0\\n\\n  def awaitTermination(timeout: Long, unit: TimeUnit): Boolean = {\\n    if (threads.exists(_ eq Thread.currentThread())) terminations.countDown() // don\\'t hang up due call in task\\n    terminations.await(timeout, unit)\\n  }\\n\\n  def execute(task: Runnable) {\\n    if (isShutdown) throw new IllegalStateException(\"Cannot execute in terminating/shutdown state\")\\n    if (task eq null) throw new NullPointerException\\n    val n = new TaskNode(task)\\n    taskHead.getAndSet(n).lazySet(n)\\n  }\\n\\n  @tailrec\\n  private def drainRemainingTasks(ts: java.util.List[Runnable]): java.util.List[Runnable] = {\\n    val tn = taskTail.get\\n    val n = tn.get\\n    if ((n ne null) && taskTail.compareAndSet(tn, n)) {\\n      ts.add(n.task)\\n      drainRemainingTasks(ts)\\n    } else ts\\n  }\\n}\\n\\nprivate class Worker(closing: AtomicInteger, taskTail: AtomicReference[TaskNode],\\n                     handler: Thread.UncaughtExceptionHandler, terminations: CountDownLatch) extends Runnable {\\n  def run() {\\n    try {\\n      doWork()\\n    } finally {\\n      terminations.countDown()\\n    }\\n  }\\n\\n  private def doWork() {\\n    while (closing.get == 0) {\\n      try {\\n        val tn = taskTail.get\\n        val n = tn.get\\n        if (n eq null) backOff()\\n        else if (taskTail.compareAndSet(tn, n)) n.run()\\n      } catch {\\n        case ex: InterruptedException => return\\n        case ex: Throwable => onError(ex)\\n      }\\n    }\\n  }\\n\\n  private def backOff() {\\n    LockSupport.parkNanos(100)\\n  }\\n\\n  private def onError(ex: Throwable) {\\n    handler.uncaughtException(Thread.currentThread(), ex)\\n  }\\n}\\n\\nprivate class TaskNode(var task: Runnable = null) extends AtomicReference[TaskNode] {\\n  def run() {\\n    task.run()\\n    task = null // to avoid holding of task reference when queue is empty\\n  }\\n}\\n```\\n\\n### Response:\\n```scala\\n', 'output_text': 'package com.github.plokhotnyuk.actors\\n\\nimport java.util.concurrent._\\nimport java.util.concurrent.atomic.{AtomicLong, AtomicReference, AtomicInteger}\\nimport java.lang.InterruptedException\\nimport scala.annotation.tailrec\\nimport java.util.concurrent.locks.LockSupport\\n\\n/**\\n * A high performance implementation of thread pool with fixed number of threads.\\n *\\n * Implementation of task queue based on non-intrusive MPSC node-based queue, described by Dmitriy Vyukov:\\n * http://www.1024cores.net/home/lock-free-algorithms/queues/non-intrusive-mpsc-node-based-queue\\n *\\n * @param threadCount a number of worker threads in pool\\n * @param threadFactory a factory to be used to build worker threads\\n * @param handler the handler for internal worker threads that will be called\\n *                in case of unrecoverable errors encountered while executing tasks.\\n */\\nclass FastThreadPoolExecutor(threadCount: Int = Runtime.getRuntime.availableProcessors(),\\n                             threadFactory: ThreadFactory = new ThreadFactory() {\\n                               def newThread(r: Runnable): Thread = new Thread(r) {\\n                                 setDaemon(true) // is it good reason: \"to avoid stalls on app end in case of missed shutdown call\"?\\n                               }\\n                             },\\n                             handler: Thread.UncaughtExceptionHandler = new Thread.UncaughtExceptionHandler() {\\n                               def uncaughtException(t: Thread, e: Throwable) {\\n                                 e.printStackTrace() // is it safe default implementation?\\n                               }\\n                             }) extends AbstractExecutorService {\\n  private val closing = new AtomicInteger(0)\\n  private val taskHead = new AtomicReference[TaskNode](new TaskNode())\\n  private val taskTail = new AtomicReference[TaskNode](taskHead.get)\\n  private val waitingThreads = new ConcurrentLinkedQueue[Thread]()\\n  private val terminations = new CountDownLatch(threadCount)\\n  private val threads = {\\n    val tf = threadFactory // to avoid creating of field for the threadFactory constructor param\\n    val c = closing  // to avoid long field names\\n    val tt = taskTail\\n    val h = handler\\n    val wt = waitingThreads\\n    val t = terminations\\n    (1 to threadCount).map(_ => tf.newThread(new Worker(c, tt, h, wt, t)))\\n  }\\n  threads.foreach(_.start())\\n\\n  def shutdown() {\\n    shutdownNow()\\n    awaitTermination(0, TimeUnit.MILLISECONDS)\\n  }\\n\\n  def shutdownNow(): java.util.List[Runnable] = {\\n    closing.set(1)\\n    threads.filter(_ ne Thread.currentThread()).foreach(_.interrupt()) // don\\'t interrupt worker thread due call in task\\n    drainRemainingTasks(new java.util.LinkedList[Runnable]())\\n  }\\n\\n  def isShutdown: Boolean = closing.get != 0\\n\\n  def isTerminated: Boolean = terminations.getCount == 0\\n\\n  def awaitTermination(timeout: Long, unit: TimeUnit): Boolean = {\\n    if (threads.exists(_ eq Thread.currentThread())) terminations.countDown() // don\\'t hang up due call in task\\n    terminations.await(timeout, unit)\\n  }\\n\\n  def execute(task: Runnable) {\\n    if (isShutdown) throw new IllegalStateException(\"Cannot execute in terminating/shutdown state\")\\n    if (task eq null) throw new NullPointerException\\n    val n = new TaskNode(task)\\n    taskHead.getAndSet(n).lazySet(n)\\n    LockSupport.unpark(waitingThreads.poll())\\n  }\\n\\n  @tailrec\\n  private def drainRemainingTasks(ts: java.util.List[Runnable]): java.util.List[Runnable] = {\\n    val tn = taskTail.get\\n    val n = tn.get\\n    if ((n ne null) && taskTail.compareAndSet(tn, n)) {\\n      ts.add(n.task)\\n      drainRemainingTasks(ts)\\n    } else ts\\n  }\\n}\\n\\nprivate class Worker(closing: AtomicInteger, taskTail: AtomicReference[TaskNode],\\n                     handler: Thread.UncaughtExceptionHandler, waitingThreads: ConcurrentLinkedQueue[Thread],\\n                     terminations: CountDownLatch) extends Runnable {\\n  private var backOffs = 0\\n\\n  def run() {\\n    try {\\n      doWork()\\n    } finally {\\n      terminations.countDown()\\n    }\\n  }\\n\\n  private def doWork() {\\n    while (closing.get == 0) {\\n      try {\\n        val tn = taskTail.get\\n        val n = tn.get\\n        if (n eq null) backOff()\\n        else if (taskTail.compareAndSet(tn, n)) execute(n)\\n      } catch {\\n        case ex: InterruptedException => return\\n        case ex: Throwable => onError(ex)\\n      }\\n    }\\n  }\\n\\n  private def execute(n: TaskNode) {\\n    n.task.run()\\n    n.task = null // to avoid holding of task reference when queue is empty\\n    backOffs = 0\\n  }\\n\\n  private def backOff() {\\n    backOffs += 1\\n    if (backOffs < 2) Thread.`yield`()\\n    else if (backOffs < 4) LockSupport.parkNanos(1L)\\n    else {\\n      waitingThreads.offer(Thread.currentThread())\\n      LockSupport.park(this)\\n    }\\n  }\\n\\n  private def onError(ex: Throwable) {\\n    handler.uncaughtException(Thread.currentThread(), ex)\\n  }\\n}\\n\\nprivate class TaskNode(var task: Runnable = null) extends AtomicReference[TaskNode]', '__index_level_0__': 43, 'input_ids': [128000, 39314, 374, 459, 7754, 430, 16964, 264, 3465, 13, 9842, 264, 2077, 430, 36001, 45695, 279, 1715, 382, 14711, 30151, 512, 59565, 1269, 279, 2728, 16148, 2068, 311, 30536, 323, 7417, 279, 4907, 10648, 13, 9842, 279, 4553, 2082, 323, 912, 1023, 1495, 304, 279, 2077, 627, 74694, 27920, 198, 1757, 470, 11267, 558, 62031, 10847, 3919, 3178, 13, 21846, 271, 475, 1674, 2013, 18456, 26546, 475, 1674, 2013, 18456, 69382, 18935, 66957, 9032, 11, 86138, 534, 475, 1674, 8178, 7522, 10802, 19357, 198, 475, 16148, 5177, 39811, 2827, 198, 475, 1674, 2013, 18456, 21679, 82, 32503, 8075, 271, 1784, 353, 362, 1579, 5178, 8292, 315, 4617, 7463, 449, 8521, 1396, 315, 14906, 627, 1235, 353, 31913, 315, 3465, 7325, 3196, 389, 2536, 3502, 376, 22784, 9599, 3624, 2494, 6108, 7325, 11, 7633, 555, 67221, 462, 88, 96100, 3178, 869, 512, 353, 1795, 1129, 2185, 13, 4278, 19, 7857, 5181, 18716, 14, 1039, 12862, 19308, 19517, 14, 77189, 92230, 3502, 376, 22784, 12, 1331, 2445, 40154, 6108, 12, 4687, 198, 1235, 353, 571, 913, 4617, 2568, 264, 1396, 315, 12128, 14906, 304, 7463, 198, 353, 571, 913, 4617, 4246, 264, 8803, 311, 387, 1511, 311, 1977, 12128, 14906, 198, 353, 571, 913, 7158, 279, 7158, 369, 5419, 12128, 14906, 430, 690, 387, 2663, 198, 353, 394, 304, 1162, 315, 38223, 3773, 481, 6103, 23926, 1418, 31320, 9256, 627, 740, 1058, 17737, 68137, 26321, 35107, 2568, 25, 1357, 284, 11195, 93715, 48211, 7575, 1105, 3227, 6663, 4617, 4246, 25, 8926, 4246, 284, 502, 8926, 4246, 368, 341, 7714, 711, 502, 6998, 2666, 25, 22887, 1680, 8926, 284, 502, 8926, 2666, 8, 341, 792, 743, 90277, 3800, 8, 443, 374, 433, 1695, 2944, 25, 330, 998, 5766, 74673, 389, 917, 842, 304, 1162, 315, 13942, 24700, 1650, 1, 5380, 7714, 457, 6663, 1173, 6663, 7158, 25, 8926, 10840, 62308, 62110, 284, 502, 8926, 10840, 62308, 62110, 368, 341, 7714, 711, 653, 62308, 1378, 1175, 25, 8926, 11, 384, 25, 22907, 8, 341, 792, 384, 8392, 368, 443, 374, 433, 6220, 1670, 8292, 5380, 7714, 457, 6663, 6547, 2289, 13822, 26321, 1898, 341, 220, 879, 1062, 15676, 284, 502, 86138, 7, 15, 340, 220, 879, 1062, 3465, 12626, 284, 502, 31416, 9032, 58, 6396, 1997, 9725, 943, 5546, 1997, 2455, 220, 879, 1062, 3465, 45895, 284, 502, 31416, 9032, 58, 6396, 1997, 9725, 8366, 12626, 673, 340, 220, 879, 1062, 10415, 811, 284, 502, 4605, 71114, 35107, 2568, 340, 220, 879, 1062, 14906, 284, 341, 262, 1062, 6543, 284, 4617, 4246, 443, 311, 5766, 6968, 315, 2115, 369, 279, 4617, 4246, 4797, 1719, 198, 262, 1062, 272, 284, 15676, 220, 443, 311, 5766, 1317, 2115, 5144, 198, 262, 1062, 18334, 284, 3465, 45895, 198, 262, 1062, 305, 284, 7158, 198, 262, 1062, 259, 284, 10415, 811, 198, 262, 320, 16, 311, 4617, 2568, 570, 2235, 2551, 591, 6543, 4721, 6998, 1792, 34186, 1361, 11, 18334, 11, 305, 11, 259, 6054, 220, 457, 220, 14906, 53281, 28290, 2527, 12647, 220, 711, 24700, 368, 341, 262, 24700, 7184, 746, 262, 2597, 21902, 33196, 7, 15, 11, 37867, 89252, 340, 220, 557, 220, 711, 24700, 7184, 4658, 1674, 2013, 5937, 58, 69936, 60, 284, 341, 262, 15676, 995, 7, 16, 340, 262, 14906, 7081, 2551, 841, 8926, 49729, 6139, 8984, 28290, 55905, 2189, 443, 1541, 956, 12956, 12128, 4617, 4245, 1650, 304, 3465, 198, 262, 24659, 55845, 26527, 1792, 1674, 2013, 55707, 58, 69936, 60, 2455, 220, 557, 220, 711, 374, 63104, 25, 7137, 284, 15676, 673, 976, 220, 15, 271, 220, 711, 374, 21902, 52299, 25, 7137, 284, 10415, 811, 54014, 624, 220, 15, 271, 220, 711, 2597, 21902, 33196, 40066, 25, 5843, 11, 5089, 25, 37867, 1680, 7137, 284, 341, 262, 422, 320, 28386, 12347, 2551, 9116, 8926, 49729, 10340, 10415, 811, 6637, 4554, 368, 443, 1541, 956, 15020, 709, 4245, 1650, 304, 3465, 198, 262, 10415, 811, 68876, 40066, 11, 5089, 340, 220, 557, 220, 711, 9203, 17941, 25, 22887, 8, 341, 262, 422, 320, 285, 63104, 8, 2571, 502, 41927, 446, 17902, 9203, 304, 71681, 15030, 18959, 1614, 1158, 262, 422, 320, 8366, 9116, 854, 8, 2571, 502, 57950, 198, 262, 1062, 308, 284, 502, 5546, 1997, 17941, 340, 262, 3465, 12626, 673, 3112, 1681, 1471, 570, 50113, 1681, 1471, 340, 220, 557, 220, 571, 14928, 2827, 198, 220, 879, 711, 24659, 55845, 26527, 36964, 25, 1674, 2013, 5937, 58, 69936, 25312, 1674, 2013, 5937, 58, 69936, 60, 284, 341, 262, 1062, 44408, 284, 3465, 45895, 673, 198, 262, 1062, 308, 284, 44408, 673, 198, 262, 422, 1819, 77, 841, 854, 8, 1024, 3465, 45895, 21263, 3112, 1681, 1175, 77, 11, 308, 595, 341, 415, 10814, 1388, 1471, 15384, 340, 415, 24659, 55845, 26527, 36964, 340, 262, 335, 775, 10814, 198, 220, 457, 633, 2039, 538, 34186, 1361, 18310, 25, 86138, 11, 3465, 45895, 25, 31416, 9032, 58, 6396, 1997, 1282, 3909, 7158, 25, 8926, 10840, 62308, 62110, 11, 10415, 811, 25, 4605, 71114, 8, 2289, 22887, 341, 220, 711, 1629, 368, 341, 262, 1456, 341, 415, 656, 6919, 746, 262, 335, 5616, 341, 415, 10415, 811, 6637, 4554, 746, 262, 457, 220, 557, 220, 879, 711, 656, 6919, 368, 341, 262, 1418, 320, 86877, 673, 624, 220, 15, 8, 341, 415, 1456, 341, 286, 1062, 44408, 284, 3465, 45895, 673, 198, 286, 1062, 308, 284, 44408, 673, 198, 286, 422, 320, 77, 9116, 854, 8, 1203, 4699, 746, 286, 775, 422, 320, 8366, 45895, 21263, 3112, 1681, 1175, 77, 11, 308, 595, 308, 7789, 746, 415, 335, 2339, 341, 286, 1162, 506, 25, 36720, 591, 471, 198, 286, 1162, 506, 25, 22907, 591, 33530, 5580, 340, 415, 457, 262, 457, 220, 557, 220, 879, 711, 1203, 4699, 368, 341, 262, 16076, 8075, 558, 847, 45, 44705, 7, 1041, 340, 220, 557, 220, 879, 711, 33530, 5580, 25, 22907, 8, 341, 262, 7158, 6441, 62308, 1378, 55153, 49729, 1535, 506, 340, 220, 457, 633, 2039, 538, 5546, 1997, 7689, 3465, 25, 22887, 284, 854, 8, 2289, 31416, 9032, 58, 6396, 1997, 60, 341, 220, 711, 1629, 368, 341, 262, 3465, 7789, 746, 262, 3465, 284, 854, 443, 311, 5766, 10168, 315, 3465, 5905, 994, 7325, 128000, 1757, 470, 11267, 558, 62031, 10847, 3919, 3178, 13, 21846, 271, 475, 1674, 2013, 18456, 26546, 475, 1674, 2013, 18456, 69382, 18935, 66957, 6720, 11, 31416, 9032, 11, 86138, 534, 475, 1674, 8178, 7522, 10802, 19357, 198, 475, 16148, 5177, 39811, 2827, 198, 475, 1674, 2013, 18456, 21679, 82, 32503, 8075, 271, 1784, 353, 362, 1579, 5178, 8292, 315, 4617, 7463, 449, 8521, 1396, 315, 14906, 627, 1235, 353, 31913, 315, 3465, 7325, 3196, 389, 2536, 3502, 376, 22784, 9599, 3624, 2494, 6108, 7325, 11, 7633, 555, 67221, 462, 88, 96100, 3178, 869, 512, 353, 1795, 1129, 2185, 13, 4278, 19, 7857, 5181, 18716, 14, 1039, 12862, 19308, 19517, 14, 77189, 92230, 3502, 376, 22784, 12, 1331, 2445, 40154, 6108, 12, 4687, 198, 1235, 353, 571, 913, 4617, 2568, 264, 1396, 315, 12128, 14906, 304, 7463, 198, 353, 571, 913, 4617, 4246, 264, 8803, 311, 387, 1511, 311, 1977, 12128, 14906, 198, 353, 571, 913, 7158, 279, 7158, 369, 5419, 12128, 14906, 430, 690, 387, 2663, 198, 353, 394, 304, 1162, 315, 38223, 3773, 481, 6103, 23926, 1418, 31320, 9256, 627, 740, 1058, 17737, 68137, 26321, 35107, 2568, 25, 1357, 284, 11195, 93715, 48211, 7575, 1105, 3227, 6663, 4617, 4246, 25, 8926, 4246, 284, 502, 8926, 4246, 368, 341, 7714, 711, 502, 6998, 2666, 25, 22887, 1680, 8926, 284, 502, 8926, 2666, 8, 341, 792, 743, 90277, 3800, 8, 443, 374, 433, 1695, 2944, 25, 330, 998, 5766, 74673, 389, 917, 842, 304, 1162, 315, 13942, 24700, 1650, 1, 5380, 7714, 457, 6663, 1173, 6663, 7158, 25, 8926, 10840, 62308, 62110, 284, 502, 8926, 10840, 62308, 62110, 368, 341, 7714, 711, 653, 62308, 1378, 1175, 25, 8926, 11, 384, 25, 22907, 8, 341, 792, 384, 8392, 368, 443, 374, 433, 6220, 1670, 8292, 5380, 7714, 457, 6663, 6547, 2289, 13822, 26321, 1898, 341, 220, 879, 1062, 15676, 284, 502, 86138, 7, 15, 340, 220, 879, 1062, 3465, 12626, 284, 502, 31416, 9032, 58, 6396, 1997, 9725, 943, 5546, 1997, 2455, 220, 879, 1062, 3465, 45895, 284, 502, 31416, 9032, 58, 6396, 1997, 9725, 8366, 12626, 673, 340, 220, 879, 1062, 8748, 39766, 284, 502, 43804, 22845, 7707, 58, 6998, 37722, 220, 879, 1062, 10415, 811, 284, 502, 4605, 71114, 35107, 2568, 340, 220, 879, 1062, 14906, 284, 341, 262, 1062, 6543, 284, 4617, 4246, 443, 311, 5766, 6968, 315, 2115, 369, 279, 4617, 4246, 4797, 1719, 198, 262, 1062, 272, 284, 15676, 220, 443, 311, 5766, 1317, 2115, 5144, 198, 262, 1062, 18334, 284, 3465, 45895, 198, 262, 1062, 305, 284, 7158, 198, 262, 1062, 41573, 284, 8748, 39766, 198, 262, 1062, 259, 284, 10415, 811, 198, 262, 320, 16, 311, 4617, 2568, 570, 2235, 2551, 591, 6543, 4721, 6998, 1792, 34186, 1361, 11, 18334, 11, 305, 11, 41573, 11, 259, 6054, 220, 457, 220, 14906, 53281, 28290, 2527, 12647, 220, 711, 24700, 368, 341, 262, 24700, 7184, 746, 262, 2597, 21902, 33196, 7, 15, 11, 37867, 89252, 340, 220, 557, 220, 711, 24700, 7184, 4658, 1674, 2013, 5937, 58, 69936, 60, 284, 341, 262, 15676, 995, 7, 16, 340, 262, 14906, 7081, 2551, 841, 8926, 49729, 6139, 8984, 28290, 55905, 2189, 443, 1541, 956, 12956, 12128, 4617, 4245, 1650, 304, 3465, 198, 262, 24659, 55845, 26527, 1792, 1674, 2013, 55707, 58, 69936, 60, 2455, 220, 557, 220, 711, 374, 63104, 25, 7137, 284, 15676, 673, 976, 220, 15, 271, 220, 711, 374, 21902, 52299, 25, 7137, 284, 10415, 811, 54014, 624, 220, 15, 271, 220, 711, 2597, 21902, 33196, 40066, 25, 5843, 11, 5089, 25, 37867, 1680, 7137, 284, 341, 262, 422, 320, 28386, 12347, 2551, 9116, 8926, 49729, 10340, 10415, 811, 6637, 4554, 368, 443, 1541, 956, 15020, 709, 4245, 1650, 304, 3465, 198, 262, 10415, 811, 68876, 40066, 11, 5089, 340, 220, 557, 220, 711, 9203, 17941, 25, 22887, 8, 341, 262, 422, 320, 285, 63104, 8, 2571, 502, 41927, 446, 17902, 9203, 304, 71681, 15030, 18959, 1614, 1158, 262, 422, 320, 8366, 9116, 854, 8, 2571, 502, 57950, 198, 262, 1062, 308, 284, 502, 5546, 1997, 17941, 340, 262, 3465, 12626, 673, 3112, 1681, 1471, 570, 50113, 1681, 1471, 340, 262, 16076, 8075, 6441, 29836, 65192, 287, 39766, 42577, 2455, 220, 557, 220, 571, 14928, 2827, 198, 220, 879, 711, 24659, 55845, 26527, 36964, 25, 1674, 2013, 5937, 58, 69936, 25312, 1674, 2013, 5937, 58, 69936, 60, 284, 341, 262, 1062, 44408, 284, 3465, 45895, 673, 198, 262, 1062, 308, 284, 44408, 673, 198, 262, 422, 1819, 77, 841, 854, 8, 1024, 3465, 45895, 21263, 3112, 1681, 1175, 77, 11, 308, 595, 341, 415, 10814, 1388, 1471, 15384, 340, 415, 24659, 55845, 26527, 36964, 340, 262, 335, 775, 10814, 198, 220, 457, 633, 2039, 538, 34186, 1361, 18310, 25, 86138, 11, 3465, 45895, 25, 31416, 9032, 58, 6396, 1997, 1282, 3909, 7158, 25, 8926, 10840, 62308, 62110, 11, 8748, 39766, 25, 43804, 22845, 7707, 58, 6998, 1282, 3909, 10415, 811, 25, 4605, 71114, 8, 2289, 22887, 341, 220, 879, 767, 1203, 4699, 82, 284, 220, 15, 271, 220, 711, 1629, 368, 341, 262, 1456, 341, 415, 656, 6919, 746, 262, 335, 5616, 341, 415, 10415, 811, 6637, 4554, 746, 262, 457, 220, 557, 220, 879, 711, 656, 6919, 368, 341, 262, 1418, 320, 86877, 673, 624, 220, 15, 8, 341, 415, 1456, 341, 286, 1062, 44408, 284, 3465, 45895, 673, 198, 286, 1062, 308, 284, 44408, 673, 198, 286, 422, 320, 77, 9116, 854, 8, 1203, 4699, 746, 286, 775, 422, 320, 8366, 45895, 21263, 3112, 1681, 1175, 77, 11, 308, 595, 9203, 1471, 340, 415, 335, 2339, 341, 286, 1162, 506, 25, 36720, 591, 471, 198, 286, 1162, 506, 25, 22907, 591, 33530, 5580, 340, 415, 457, 262, 457, 220, 557, 220, 879, 711, 9203, 1471, 25, 5546, 1997, 8, 341, 262, 308, 15384, 7789, 746, 262, 308, 15384, 284, 854, 443, 311, 5766, 10168, 315, 3465, 5905, 994, 7325, 374, 4384, 198, 262, 1203, 4699, 82, 284, 220, 15, 198, 220, 557, 220, 879, 711, 1203, 4699, 368, 341, 262, 1203, 4699, 82, 1447, 220, 16, 198, 262, 422, 320, 1445, 4699, 82, 366, 220, 17, 8, 8926, 15254, 30796, 63, 746, 262, 775, 422, 320, 1445], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [128000, 39314, 374, 459, 7754, 430, 16964, 264, 3465, 13, 9842, 264, 2077, 430, 36001, 45695, 279, 1715, 382, 14711, 30151, 512, 59565, 1269, 279, 2728, 16148, 2068, 311, 30536, 323, 7417, 279, 4907, 10648, 13, 9842, 279, 4553, 2082, 323, 912, 1023, 1495, 304, 279, 2077, 627, 74694, 27920, 198, 1757, 470, 11267, 558, 62031, 10847, 3919, 3178, 13, 21846, 271, 475, 1674, 2013, 18456, 26546, 475, 1674, 2013, 18456, 69382, 18935, 66957, 9032, 11, 86138, 534, 475, 1674, 8178, 7522, 10802, 19357, 198, 475, 16148, 5177, 39811, 2827, 198, 475, 1674, 2013, 18456, 21679, 82, 32503, 8075, 271, 1784, 353, 362, 1579, 5178, 8292, 315, 4617, 7463, 449, 8521, 1396, 315, 14906, 627, 1235, 353, 31913, 315, 3465, 7325, 3196, 389, 2536, 3502, 376, 22784, 9599, 3624, 2494, 6108, 7325, 11, 7633, 555, 67221, 462, 88, 96100, 3178, 869, 512, 353, 1795, 1129, 2185, 13, 4278, 19, 7857, 5181, 18716, 14, 1039, 12862, 19308, 19517, 14, 77189, 92230, 3502, 376, 22784, 12, 1331, 2445, 40154, 6108, 12, 4687, 198, 1235, 353, 571, 913, 4617, 2568, 264, 1396, 315, 12128, 14906, 304, 7463, 198, 353, 571, 913, 4617, 4246, 264, 8803, 311, 387, 1511, 311, 1977, 12128, 14906, 198, 353, 571, 913, 7158, 279, 7158, 369, 5419, 12128, 14906, 430, 690, 387, 2663, 198, 353, 394, 304, 1162, 315, 38223, 3773, 481, 6103, 23926, 1418, 31320, 9256, 627, 740, 1058, 17737, 68137, 26321, 35107, 2568, 25, 1357, 284, 11195, 93715, 48211, 7575, 1105, 3227, 6663, 4617, 4246, 25, 8926, 4246, 284, 502, 8926, 4246, 368, 341, 7714, 711, 502, 6998, 2666, 25, 22887, 1680, 8926, 284, 502, 8926, 2666, 8, 341, 792, 743, 90277, 3800, 8, 443, 374, 433, 1695, 2944, 25, 330, 998, 5766, 74673, 389, 917, 842, 304, 1162, 315, 13942, 24700, 1650, 1, 5380, 7714, 457, 6663, 1173, 6663, 7158, 25, 8926, 10840, 62308, 62110, 284, 502, 8926, 10840, 62308, 62110, 368, 341, 7714, 711, 653, 62308, 1378, 1175, 25, 8926, 11, 384, 25, 22907, 8, 341, 792, 384, 8392, 368, 443, 374, 433, 6220, 1670, 8292, 5380, 7714, 457, 6663, 6547, 2289, 13822, 26321, 1898, 341, 220, 879, 1062, 15676, 284, 502, 86138, 7, 15, 340, 220, 879, 1062, 3465, 12626, 284, 502, 31416, 9032, 58, 6396, 1997, 9725, 943, 5546, 1997, 2455, 220, 879, 1062, 3465, 45895, 284, 502, 31416, 9032, 58, 6396, 1997, 9725, 8366, 12626, 673, 340, 220, 879, 1062, 10415, 811, 284, 502, 4605, 71114, 35107, 2568, 340, 220, 879, 1062, 14906, 284, 341, 262, 1062, 6543, 284, 4617, 4246, 443, 311, 5766, 6968, 315, 2115, 369, 279, 4617, 4246, 4797, 1719, 198, 262, 1062, 272, 284, 15676, 220, 443, 311, 5766, 1317, 2115, 5144, 198, 262, 1062, 18334, 284, 3465, 45895, 198, 262, 1062, 305, 284, 7158, 198, 262, 1062, 259, 284, 10415, 811, 198, 262, 320, 16, 311, 4617, 2568, 570, 2235, 2551, 591, 6543, 4721, 6998, 1792, 34186, 1361, 11, 18334, 11, 305, 11, 259, 6054, 220, 457, 220, 14906, 53281, 28290, 2527, 12647, 220, 711, 24700, 368, 341, 262, 24700, 7184, 746, 262, 2597, 21902, 33196, 7, 15, 11, 37867, 89252, 340, 220, 557, 220, 711, 24700, 7184, 4658, 1674, 2013, 5937, 58, 69936, 60, 284, 341, 262, 15676, 995, 7, 16, 340, 262, 14906, 7081, 2551, 841, 8926, 49729, 6139, 8984, 28290, 55905, 2189, 443, 1541, 956, 12956, 12128, 4617, 4245, 1650, 304, 3465, 198, 262, 24659, 55845, 26527, 1792, 1674, 2013, 55707, 58, 69936, 60, 2455, 220, 557, 220, 711, 374, 63104, 25, 7137, 284, 15676, 673, 976, 220, 15, 271, 220, 711, 374, 21902, 52299, 25, 7137, 284, 10415, 811, 54014, 624, 220, 15, 271, 220, 711, 2597, 21902, 33196, 40066, 25, 5843, 11, 5089, 25, 37867, 1680, 7137, 284, 341, 262, 422, 320, 28386, 12347, 2551, 9116, 8926, 49729, 10340, 10415, 811, 6637, 4554, 368, 443, 1541, 956, 15020, 709, 4245, 1650, 304, 3465, 198, 262, 10415, 811, 68876, 40066, 11, 5089, 340, 220, 557, 220, 711, 9203, 17941, 25, 22887, 8, 341, 262, 422, 320, 285, 63104, 8, 2571, 502, 41927, 446, 17902, 9203, 304, 71681, 15030, 18959, 1614, 1158, 262, 422, 320, 8366, 9116, 854, 8, 2571, 502, 57950, 198, 262, 1062, 308, 284, 502, 5546, 1997, 17941, 340, 262, 3465, 12626, 673, 3112, 1681, 1471, 570, 50113, 1681, 1471, 340, 220, 557, 220, 571, 14928, 2827, 198, 220, 879, 711, 24659, 55845, 26527, 36964, 25, 1674, 2013, 5937, 58, 69936, 25312, 1674, 2013, 5937, 58, 69936, 60, 284, 341, 262, 1062, 44408, 284, 3465, 45895, 673, 198, 262, 1062, 308, 284, 44408, 673, 198, 262, 422, 1819, 77, 841, 854, 8, 1024, 3465, 45895, 21263, 3112, 1681, 1175, 77, 11, 308, 595, 341, 415, 10814, 1388, 1471, 15384, 340, 415, 24659, 55845, 26527, 36964, 340, 262, 335, 775, 10814, 198, 220, 457, 633, 2039, 538, 34186, 1361, 18310, 25, 86138, 11, 3465, 45895, 25, 31416, 9032, 58, 6396, 1997, 1282, 3909, 7158, 25, 8926, 10840, 62308, 62110, 11, 10415, 811, 25, 4605, 71114, 8, 2289, 22887, 341, 220, 711, 1629, 368, 341, 262, 1456, 341, 415, 656, 6919, 746, 262, 335, 5616, 341, 415, 10415, 811, 6637, 4554, 746, 262, 457, 220, 557, 220, 879, 711, 656, 6919, 368, 341, 262, 1418, 320, 86877, 673, 624, 220, 15, 8, 341, 415, 1456, 341, 286, 1062, 44408, 284, 3465, 45895, 673, 198, 286, 1062, 308, 284, 44408, 673, 198, 286, 422, 320, 77, 9116, 854, 8, 1203, 4699, 746, 286, 775, 422, 320, 8366, 45895, 21263, 3112, 1681, 1175, 77, 11, 308, 595, 308, 7789, 746, 415, 335, 2339, 341, 286, 1162, 506, 25, 36720, 591, 471, 198, 286, 1162, 506, 25, 22907, 591, 33530, 5580, 340, 415, 457, 262, 457, 220, 557, 220, 879, 711, 1203, 4699, 368, 341, 262, 16076, 8075, 558, 847, 45, 44705, 7, 1041, 340, 220, 557, 220, 879, 711, 33530, 5580, 25, 22907, 8, 341, 262, 7158, 6441, 62308, 1378, 55153, 49729, 1535, 506, 340, 220, 457, 633, 2039, 538, 5546, 1997, 7689, 3465, 25, 22887, 284, 854, 8, 2289, 31416, 9032, 58, 6396, 1997, 60, 341, 220, 711, 1629, 368, 341, 262, 3465, 7789, 746, 262, 3465, 284, 854, 443, 311, 5766, 10168, 315, 3465, 5905, 994, 7325, 128000, 1757, 470, 11267, 558, 62031, 10847, 3919, 3178, 13, 21846, 271, 475, 1674, 2013, 18456, 26546, 475, 1674, 2013, 18456, 69382, 18935, 66957, 6720, 11, 31416, 9032, 11, 86138, 534, 475, 1674, 8178, 7522, 10802, 19357, 198, 475, 16148, 5177, 39811, 2827, 198, 475, 1674, 2013, 18456, 21679, 82, 32503, 8075, 271, 1784, 353, 362, 1579, 5178, 8292, 315, 4617, 7463, 449, 8521, 1396, 315, 14906, 627, 1235, 353, 31913, 315, 3465, 7325, 3196, 389, 2536, 3502, 376, 22784, 9599, 3624, 2494, 6108, 7325, 11, 7633, 555, 67221, 462, 88, 96100, 3178, 869, 512, 353, 1795, 1129, 2185, 13, 4278, 19, 7857, 5181, 18716, 14, 1039, 12862, 19308, 19517, 14, 77189, 92230, 3502, 376, 22784, 12, 1331, 2445, 40154, 6108, 12, 4687, 198, 1235, 353, 571, 913, 4617, 2568, 264, 1396, 315, 12128, 14906, 304, 7463, 198, 353, 571, 913, 4617, 4246, 264, 8803, 311, 387, 1511, 311, 1977, 12128, 14906, 198, 353, 571, 913, 7158, 279, 7158, 369, 5419, 12128, 14906, 430, 690, 387, 2663, 198, 353, 394, 304, 1162, 315, 38223, 3773, 481, 6103, 23926, 1418, 31320, 9256, 627, 740, 1058, 17737, 68137, 26321, 35107, 2568, 25, 1357, 284, 11195, 93715, 48211, 7575, 1105, 3227, 6663, 4617, 4246, 25, 8926, 4246, 284, 502, 8926, 4246, 368, 341, 7714, 711, 502, 6998, 2666, 25, 22887, 1680, 8926, 284, 502, 8926, 2666, 8, 341, 792, 743, 90277, 3800, 8, 443, 374, 433, 1695, 2944, 25, 330, 998, 5766, 74673, 389, 917, 842, 304, 1162, 315, 13942, 24700, 1650, 1, 5380, 7714, 457, 6663, 1173, 6663, 7158, 25, 8926, 10840, 62308, 62110, 284, 502, 8926, 10840, 62308, 62110, 368, 341, 7714, 711, 653, 62308, 1378, 1175, 25, 8926, 11, 384, 25, 22907, 8, 341, 792, 384, 8392, 368, 443, 374, 433, 6220, 1670, 8292, 5380, 7714, 457, 6663, 6547, 2289, 13822, 26321, 1898, 341, 220, 879, 1062, 15676, 284, 502, 86138, 7, 15, 340, 220, 879, 1062, 3465, 12626, 284, 502, 31416, 9032, 58, 6396, 1997, 9725, 943, 5546, 1997, 2455, 220, 879, 1062, 3465, 45895, 284, 502, 31416, 9032, 58, 6396, 1997, 9725, 8366, 12626, 673, 340, 220, 879, 1062, 8748, 39766, 284, 502, 43804, 22845, 7707, 58, 6998, 37722, 220, 879, 1062, 10415, 811, 284, 502, 4605, 71114, 35107, 2568, 340, 220, 879, 1062, 14906, 284, 341, 262, 1062, 6543, 284, 4617, 4246, 443, 311, 5766, 6968, 315, 2115, 369, 279, 4617, 4246, 4797, 1719, 198, 262, 1062, 272, 284, 15676, 220, 443, 311, 5766, 1317, 2115, 5144, 198, 262, 1062, 18334, 284, 3465, 45895, 198, 262, 1062, 305, 284, 7158, 198, 262, 1062, 41573, 284, 8748, 39766, 198, 262, 1062, 259, 284, 10415, 811, 198, 262, 320, 16, 311, 4617, 2568, 570, 2235, 2551, 591, 6543, 4721, 6998, 1792, 34186, 1361, 11, 18334, 11, 305, 11, 41573, 11, 259, 6054, 220, 457, 220, 14906, 53281, 28290, 2527, 12647, 220, 711, 24700, 368, 341, 262, 24700, 7184, 746, 262, 2597, 21902, 33196, 7, 15, 11, 37867, 89252, 340, 220, 557, 220, 711, 24700, 7184, 4658, 1674, 2013, 5937, 58, 69936, 60, 284, 341, 262, 15676, 995, 7, 16, 340, 262, 14906, 7081, 2551, 841, 8926, 49729, 6139, 8984, 28290, 55905, 2189, 443, 1541, 956, 12956, 12128, 4617, 4245, 1650, 304, 3465, 198, 262, 24659, 55845, 26527, 1792, 1674, 2013, 55707, 58, 69936, 60, 2455, 220, 557, 220, 711, 374, 63104, 25, 7137, 284, 15676, 673, 976, 220, 15, 271, 220, 711, 374, 21902, 52299, 25, 7137, 284, 10415, 811, 54014, 624, 220, 15, 271, 220, 711, 2597, 21902, 33196, 40066, 25, 5843, 11, 5089, 25, 37867, 1680, 7137, 284, 341, 262, 422, 320, 28386, 12347, 2551, 9116, 8926, 49729, 10340, 10415, 811, 6637, 4554, 368, 443, 1541, 956, 15020, 709, 4245, 1650, 304, 3465, 198, 262, 10415, 811, 68876, 40066, 11, 5089, 340, 220, 557, 220, 711, 9203, 17941, 25, 22887, 8, 341, 262, 422, 320, 285, 63104, 8, 2571, 502, 41927, 446, 17902, 9203, 304, 71681, 15030, 18959, 1614, 1158, 262, 422, 320, 8366, 9116, 854, 8, 2571, 502, 57950, 198, 262, 1062, 308, 284, 502, 5546, 1997, 17941, 340, 262, 3465, 12626, 673, 3112, 1681, 1471, 570, 50113, 1681, 1471, 340, 262, 16076, 8075, 6441, 29836, 65192, 287, 39766, 42577, 2455, 220, 557, 220, 571, 14928, 2827, 198, 220, 879, 711, 24659, 55845, 26527, 36964, 25, 1674, 2013, 5937, 58, 69936, 25312, 1674, 2013, 5937, 58, 69936, 60, 284, 341, 262, 1062, 44408, 284, 3465, 45895, 673, 198, 262, 1062, 308, 284, 44408, 673, 198, 262, 422, 1819, 77, 841, 854, 8, 1024, 3465, 45895, 21263, 3112, 1681, 1175, 77, 11, 308, 595, 341, 415, 10814, 1388, 1471, 15384, 340, 415, 24659, 55845, 26527, 36964, 340, 262, 335, 775, 10814, 198, 220, 457, 633, 2039, 538, 34186, 1361, 18310, 25, 86138, 11, 3465, 45895, 25, 31416, 9032, 58, 6396, 1997, 1282, 3909, 7158, 25, 8926, 10840, 62308, 62110, 11, 8748, 39766, 25, 43804, 22845, 7707, 58, 6998, 1282, 3909, 10415, 811, 25, 4605, 71114, 8, 2289, 22887, 341, 220, 879, 767, 1203, 4699, 82, 284, 220, 15, 271, 220, 711, 1629, 368, 341, 262, 1456, 341, 415, 656, 6919, 746, 262, 335, 5616, 341, 415, 10415, 811, 6637, 4554, 746, 262, 457, 220, 557, 220, 879, 711, 656, 6919, 368, 341, 262, 1418, 320, 86877, 673, 624, 220, 15, 8, 341, 415, 1456, 341, 286, 1062, 44408, 284, 3465, 45895, 673, 198, 286, 1062, 308, 284, 44408, 673, 198, 286, 422, 320, 77, 9116, 854, 8, 1203, 4699, 746, 286, 775, 422, 320, 8366, 45895, 21263, 3112, 1681, 1175, 77, 11, 308, 595, 9203, 1471, 340, 415, 335, 2339, 341, 286, 1162, 506, 25, 36720, 591, 471, 198, 286, 1162, 506, 25, 22907, 591, 33530, 5580, 340, 415, 457, 262, 457, 220, 557, 220, 879, 711, 9203, 1471, 25, 5546, 1997, 8, 341, 262, 308, 15384, 7789, 746, 262, 308, 15384, 284, 854, 443, 311, 5766, 10168, 315, 3465, 5905, 994, 7325, 374, 4384, 198, 262, 1203, 4699, 82, 284, 220, 15, 198, 220, 557, 220, 879, 711, 1203, 4699, 368, 341, 262, 1203, 4699, 82, 1447, 220, 16, 198, 262, 422, 320, 1445, 4699, 82, 366, 220, 17, 8, 8926, 15254, 30796, 63, 746, 262, 775, 422, 320, 1445]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor(test_data['input_ids'])\n",
        "# print(torch.device(\"cuda\"))\n",
        "inputs = inputs.to(device='cuda')\n",
        "print(inputs.device)\n",
        "output = model.generate(input_ids=inputs, max_length=2048, max_new_tokens=2048, num_beams=5)\n",
        "generation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generation)"
      ],
      "metadata": {
        "id": "D-xkaSwTZwVh",
        "outputId": "6d12f1ce-0766-4ea4-bf9c-aec8d343a9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Both `max_new_tokens` (=2048) and `max_length`(=2048) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacity of 14.75 GiB of which 2.90 GiB is free. Process 121111 has 11.84 GiB memory in use. Of the allocated memory 11.13 GiB is allocated by PyTorch, and 591.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-4207043bf5c7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mgeneration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2245\u001b[0m             \u001b[0;31m# 13. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2246\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2247\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2248\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3454\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Unchanged original behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3455\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1191\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    943\u001b[0m                 )\n\u001b[1;32m    944\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    946\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2378\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2380\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacity of 14.75 GiB of which 2.90 GiB is free. Process 121111 has 11.84 GiB memory in use. Of the allocated memory 11.13 GiB is allocated by PyTorch, and 591.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "generations = []\n",
        "for i in range(len(test_data)):\n",
        "  output = model.generate(test_data[i]['input_ids'], max_new_tokens=2048)\n",
        "  generation = tokenizer.decode(output)"
      ],
      "metadata": {
        "id": "SAiFxnKFZELQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf4a8fc98df04e62b4bada6cfef03252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42b2be32010c4ed9bd00e49817251f59",
              "IPY_MODEL_b9b74f4f80414054b00c48becdbc7d6e",
              "IPY_MODEL_78089d3046c442aab80d19305ea83f09"
            ],
            "layout": "IPY_MODEL_01d19a1ab1934f5caf313efc3509a3f5"
          }
        },
        "42b2be32010c4ed9bd00e49817251f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e185d149be27449aaffc0a4dafcba9bb",
            "placeholder": "​",
            "style": "IPY_MODEL_edf4781a51444d3daa93ae852a500387",
            "value": "Creating json from Arrow format: 100%"
          }
        },
        "b9b74f4f80414054b00c48becdbc7d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5709e4419b46493895b25f75902c98cd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb8418e17799497c93a69e9d23636ca2",
            "value": 1
          }
        },
        "78089d3046c442aab80d19305ea83f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aac7ff8a95c646089d310fa715c5e441",
            "placeholder": "​",
            "style": "IPY_MODEL_eb635866886943a9bcbf4aa6186ff525",
            "value": " 1/1 [00:00&lt;00:00,  8.97ba/s]"
          }
        },
        "01d19a1ab1934f5caf313efc3509a3f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e185d149be27449aaffc0a4dafcba9bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf4781a51444d3daa93ae852a500387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5709e4419b46493895b25f75902c98cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb8418e17799497c93a69e9d23636ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aac7ff8a95c646089d310fa715c5e441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb635866886943a9bcbf4aa6186ff525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a619b2c8d416447880262fd79ff8e66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56b075ed2c554d8f8acb441776447fda",
              "IPY_MODEL_e531ea4f9a864609b3cb00f68b5546e7",
              "IPY_MODEL_24f79dcf49654c8f8cd33e881e711daa"
            ],
            "layout": "IPY_MODEL_1481cc9b6896464b8c5064368e0ea09e"
          }
        },
        "56b075ed2c554d8f8acb441776447fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9109c8fe80e74ee987b0a18f72d74ba4",
            "placeholder": "​",
            "style": "IPY_MODEL_daf4121a586b461ebd40c7a147a2c63b",
            "value": "Creating json from Arrow format: 100%"
          }
        },
        "e531ea4f9a864609b3cb00f68b5546e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_888d9568d50344c78f70375fbccbec3c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6cf7243ea46a41099f44dcc7042a2ff3",
            "value": 1
          }
        },
        "24f79dcf49654c8f8cd33e881e711daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7c97bd94f574c61b3fea569f8b355b3",
            "placeholder": "​",
            "style": "IPY_MODEL_88551b7fd9674ea8af47a530c43eb233",
            "value": " 1/1 [00:00&lt;00:00, 29.11ba/s]"
          }
        },
        "1481cc9b6896464b8c5064368e0ea09e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9109c8fe80e74ee987b0a18f72d74ba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daf4121a586b461ebd40c7a147a2c63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "888d9568d50344c78f70375fbccbec3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cf7243ea46a41099f44dcc7042a2ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7c97bd94f574c61b3fea569f8b355b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88551b7fd9674ea8af47a530c43eb233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f5405f2aa7740c7b1935e6e8ee65d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3162cdc1289f410aa1a5d48bf6a86156",
              "IPY_MODEL_860af43f3794425e8ed384b83f7d8b79",
              "IPY_MODEL_e7f6db0fd22341b79da0d62be63ebff7"
            ],
            "layout": "IPY_MODEL_d6fa0bae33b04972a49a6e6b94dbc102"
          }
        },
        "3162cdc1289f410aa1a5d48bf6a86156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ddcb05e4d80425f8612f01f80be0374",
            "placeholder": "​",
            "style": "IPY_MODEL_86953d7f6aa14e1695debc01edfdb71b",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "860af43f3794425e8ed384b83f7d8b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faf7abc5f6cf49ed869467ca141982b4",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bed1b43be524dfab180ef1ae274908b",
            "value": 40
          }
        },
        "e7f6db0fd22341b79da0d62be63ebff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44056bfce3cf47968f7f81320f73e946",
            "placeholder": "​",
            "style": "IPY_MODEL_5e8042fbc54c40acab6be32238eaeb71",
            "value": " 40/40 [00:00&lt;00:00, 715.42 examples/s]"
          }
        },
        "d6fa0bae33b04972a49a6e6b94dbc102": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ddcb05e4d80425f8612f01f80be0374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86953d7f6aa14e1695debc01edfdb71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faf7abc5f6cf49ed869467ca141982b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bed1b43be524dfab180ef1ae274908b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44056bfce3cf47968f7f81320f73e946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e8042fbc54c40acab6be32238eaeb71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44918da3e5874238b664a03ed0404798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7f1db956da7420dbd73f6c2b69acb4b",
              "IPY_MODEL_3e7206fdcc5f49f2922d50d714e4f1c8",
              "IPY_MODEL_635650efd6634d7295af33419edc7b0d"
            ],
            "layout": "IPY_MODEL_11cdf58f8dd34cfd98e8a570ce7e8d34"
          }
        },
        "a7f1db956da7420dbd73f6c2b69acb4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_240bf1845a8b48f3a7a2e503a7dec027",
            "placeholder": "​",
            "style": "IPY_MODEL_0452fd6249cd498ca1bc6b3f124c3b14",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "3e7206fdcc5f49f2922d50d714e4f1c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_befda373881e489680d7450ddf8fdb77",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e4a3a95a13d417aa2b6a87de1a34644",
            "value": 11
          }
        },
        "635650efd6634d7295af33419edc7b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e96aa98e1174cd990097b48723307f4",
            "placeholder": "​",
            "style": "IPY_MODEL_4cda2725820e49aebcc7e4bb4657ef05",
            "value": " 11/11 [00:00&lt;00:00, 256.59 examples/s]"
          }
        },
        "11cdf58f8dd34cfd98e8a570ce7e8d34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "240bf1845a8b48f3a7a2e503a7dec027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0452fd6249cd498ca1bc6b3f124c3b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "befda373881e489680d7450ddf8fdb77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e4a3a95a13d417aa2b6a87de1a34644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e96aa98e1174cd990097b48723307f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cda2725820e49aebcc7e4bb4657ef05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe73ec2d01ab4ceca0aeb92b6d8eaa7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_321969f574ae4a64bbba6104654d515b",
              "IPY_MODEL_9a12a22f6fa14a29aec2e351ebb8617b",
              "IPY_MODEL_d7009d7a676d4437b53ed6e09c6a08c5"
            ],
            "layout": "IPY_MODEL_46bf1c5eca9e458caf5db7a2edee4e5e"
          }
        },
        "321969f574ae4a64bbba6104654d515b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f23bbd8e0d314817bdcf2345f29234ac",
            "placeholder": "​",
            "style": "IPY_MODEL_2bd44ca625574c8f8df461f7ee6cc18c",
            "value": "Map: 100%"
          }
        },
        "9a12a22f6fa14a29aec2e351ebb8617b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e120cdb406a0491d8d5f7814eb131f32",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f320d8024e27465cbc41dd5597f2804d",
            "value": 40
          }
        },
        "d7009d7a676d4437b53ed6e09c6a08c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5ea9465689e45ddb327b57472687267",
            "placeholder": "​",
            "style": "IPY_MODEL_da3145c5105144f388c362c2a6987f9e",
            "value": " 40/40 [00:00&lt;00:00, 98.79 examples/s]"
          }
        },
        "46bf1c5eca9e458caf5db7a2edee4e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f23bbd8e0d314817bdcf2345f29234ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bd44ca625574c8f8df461f7ee6cc18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e120cdb406a0491d8d5f7814eb131f32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f320d8024e27465cbc41dd5597f2804d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5ea9465689e45ddb327b57472687267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da3145c5105144f388c362c2a6987f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6451041189044413b8c08d307435766b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce1b317345df48f1839f51bf12a94521",
              "IPY_MODEL_ef56828524c74e96a64fe12575fd6816",
              "IPY_MODEL_7135afea2e444873b9b5f84f9e99c78d"
            ],
            "layout": "IPY_MODEL_1f37c6eaaf894019b499bffdce5f42dd"
          }
        },
        "ce1b317345df48f1839f51bf12a94521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cdaf3fcf3a04a71be37885298218fea",
            "placeholder": "​",
            "style": "IPY_MODEL_3bbfde88f1604e62bd59afc5d5907da3",
            "value": "Map: 100%"
          }
        },
        "ef56828524c74e96a64fe12575fd6816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_824365f08e4543b3b30ed9ab2309d8d5",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eacf93bd91e64fbea3365a69fe67b458",
            "value": 40
          }
        },
        "7135afea2e444873b9b5f84f9e99c78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abca4adaaa5248479416a519be551ee7",
            "placeholder": "​",
            "style": "IPY_MODEL_6d7dc0e5845042e9844129cf715a1a3b",
            "value": " 40/40 [00:00&lt;00:00, 364.73 examples/s]"
          }
        },
        "1f37c6eaaf894019b499bffdce5f42dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cdaf3fcf3a04a71be37885298218fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bbfde88f1604e62bd59afc5d5907da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "824365f08e4543b3b30ed9ab2309d8d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eacf93bd91e64fbea3365a69fe67b458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abca4adaaa5248479416a519be551ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7dc0e5845042e9844129cf715a1a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db35c54fa2af4cc58c9659e2e4355547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e2d8b3361124a9aa1f1a7a14f6f749a",
              "IPY_MODEL_6554afe8c5164e4bbc7f2b22f9a611ad",
              "IPY_MODEL_2adc01d935af40f7bfab9d1545ecd6cc"
            ],
            "layout": "IPY_MODEL_47c7ebbd78bf47128d11f701a329b26f"
          }
        },
        "4e2d8b3361124a9aa1f1a7a14f6f749a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cb8e0d984014c51bf829b2c3b4e9cc4",
            "placeholder": "​",
            "style": "IPY_MODEL_d8411fa689e94926a784ac7245f6582a",
            "value": "Map: 100%"
          }
        },
        "6554afe8c5164e4bbc7f2b22f9a611ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6e8bdf568f047e1a963c163eeb8a954",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2533e059ed6044c19d5be3361d0c7889",
            "value": 11
          }
        },
        "2adc01d935af40f7bfab9d1545ecd6cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cff264372ac343ac868200d9411c2c32",
            "placeholder": "​",
            "style": "IPY_MODEL_ce60e917e46a429287b89a20353150e0",
            "value": " 11/11 [00:00&lt;00:00, 78.23 examples/s]"
          }
        },
        "47c7ebbd78bf47128d11f701a329b26f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cb8e0d984014c51bf829b2c3b4e9cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8411fa689e94926a784ac7245f6582a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6e8bdf568f047e1a963c163eeb8a954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2533e059ed6044c19d5be3361d0c7889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cff264372ac343ac868200d9411c2c32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce60e917e46a429287b89a20353150e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51ab391727db43c89b3f2cff1ecf425c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2cf7939826e34b0b9ec77bdd47aa4688",
              "IPY_MODEL_b16ececf7ee94d26a58aa539cc10aaed",
              "IPY_MODEL_55a4b95f8c734f05aaff75233a96a381"
            ],
            "layout": "IPY_MODEL_a6579822db994199be9d8539636ef3ad"
          }
        },
        "2cf7939826e34b0b9ec77bdd47aa4688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d391e8eca344fa985fa3c6429d5b2a3",
            "placeholder": "​",
            "style": "IPY_MODEL_867f9a49680541e982fb86833f6a1bfb",
            "value": "Map: 100%"
          }
        },
        "b16ececf7ee94d26a58aa539cc10aaed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_366e8e93ca254cc0976c2fb5b8612a9b",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32a9cd52a9c341e3ac0b7b0266868dc5",
            "value": 11
          }
        },
        "55a4b95f8c734f05aaff75233a96a381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ba81dc9e7234b39b6d6acb101ac81ef",
            "placeholder": "​",
            "style": "IPY_MODEL_68d24611e73a4f63991c53e28b3d91a9",
            "value": " 11/11 [00:00&lt;00:00, 186.83 examples/s]"
          }
        },
        "a6579822db994199be9d8539636ef3ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d391e8eca344fa985fa3c6429d5b2a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "867f9a49680541e982fb86833f6a1bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "366e8e93ca254cc0976c2fb5b8612a9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a9cd52a9c341e3ac0b7b0266868dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ba81dc9e7234b39b6d6acb101ac81ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d24611e73a4f63991c53e28b3d91a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}