{
  "problem_idx": "2497",
  "metrics": {
    "bleu_score": 0.24772129668125484,
    "edit_similarity": 0.43775933609958506,
    "ast_similarity": 0.6896551724137931,
    "diff_bleu_score": 1.0
  },
  "inefficient_solution": "class Solution:\n    def maxStarSum(self, vals, edges, k):\n        n = len(vals)\n        g = [[0]*n for _ in range(n)]\n        for i in range(n):\n            g[i] = [0]*n\n        for a, b in edges:\n            g[a][b] = vals[b]\n            g[b][a] = vals[a]\n\n        max_sum = 0\n        for i in range(n):\n            neighbors = sorted(g[i], reverse=True)[:k]\n            neighbor_sum = sum(neighbors)\n            max_sum = max(max_sum, vals[i] + neighbor_sum)\n\n        return max_sum",
  "canonical_solution": "class Solution:\n    def maxStarSum(self, vals: List[int], edges: List[List[int]], k: int) -> int:\n        g = defaultdict(list)\n        for a, b in edges:\n            if vals[b] > 0:\n                g[a].append(vals[b])\n            if vals[a] > 0:\n                g[b].append(vals[a])\n        for bs in g.values():\n            bs.sort(reverse=True)\n        return max(v + sum(g[i][:k]) for i, v in enumerate(vals))\n",
  "is_python": true
}